{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTwRtUvWnqh3ig3L3qX7CC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VeronikaShe/ML-study_HW_1/blob/main/HW_4_Log_Nest_RMS_GRAD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PQ91uuFG8mj"
      },
      "source": [
        "- Загружаем данные.\n",
        "\n",
        "- Используем датасет с ирисами. Оставляем только 2 класса: Iris Versicolor, Iris Virginica.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV3A-0MtG8mW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57136cd5-8776-4cd3-a0cb-410c29e662a1"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd # Для работы с данными\n",
        "import scipy.stats # При работе со статистикой\n",
        "import matplotlib.pyplot as plt  # Библиотека для визуализации результатов\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "!pip install category_encoders\n",
        "from category_encoders.count import CountEncoder"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.8.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.16.0)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "Downloading category_encoders-2.8.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "pho_bO5I4lbV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "iris"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "967w4IEy4uww",
        "outputId": "49b2b24a-c055-4241-c682-5bc6c815d1bd"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
              "        [4.9, 3. , 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.3, 0.2],\n",
              "        [4.6, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.6, 1.4, 0.2],\n",
              "        [5.4, 3.9, 1.7, 0.4],\n",
              "        [4.6, 3.4, 1.4, 0.3],\n",
              "        [5. , 3.4, 1.5, 0.2],\n",
              "        [4.4, 2.9, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.1],\n",
              "        [5.4, 3.7, 1.5, 0.2],\n",
              "        [4.8, 3.4, 1.6, 0.2],\n",
              "        [4.8, 3. , 1.4, 0.1],\n",
              "        [4.3, 3. , 1.1, 0.1],\n",
              "        [5.8, 4. , 1.2, 0.2],\n",
              "        [5.7, 4.4, 1.5, 0.4],\n",
              "        [5.4, 3.9, 1.3, 0.4],\n",
              "        [5.1, 3.5, 1.4, 0.3],\n",
              "        [5.7, 3.8, 1.7, 0.3],\n",
              "        [5.1, 3.8, 1.5, 0.3],\n",
              "        [5.4, 3.4, 1.7, 0.2],\n",
              "        [5.1, 3.7, 1.5, 0.4],\n",
              "        [4.6, 3.6, 1. , 0.2],\n",
              "        [5.1, 3.3, 1.7, 0.5],\n",
              "        [4.8, 3.4, 1.9, 0.2],\n",
              "        [5. , 3. , 1.6, 0.2],\n",
              "        [5. , 3.4, 1.6, 0.4],\n",
              "        [5.2, 3.5, 1.5, 0.2],\n",
              "        [5.2, 3.4, 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.6, 0.2],\n",
              "        [4.8, 3.1, 1.6, 0.2],\n",
              "        [5.4, 3.4, 1.5, 0.4],\n",
              "        [5.2, 4.1, 1.5, 0.1],\n",
              "        [5.5, 4.2, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.2, 1.2, 0.2],\n",
              "        [5.5, 3.5, 1.3, 0.2],\n",
              "        [4.9, 3.6, 1.4, 0.1],\n",
              "        [4.4, 3. , 1.3, 0.2],\n",
              "        [5.1, 3.4, 1.5, 0.2],\n",
              "        [5. , 3.5, 1.3, 0.3],\n",
              "        [4.5, 2.3, 1.3, 0.3],\n",
              "        [4.4, 3.2, 1.3, 0.2],\n",
              "        [5. , 3.5, 1.6, 0.6],\n",
              "        [5.1, 3.8, 1.9, 0.4],\n",
              "        [4.8, 3. , 1.4, 0.3],\n",
              "        [5.1, 3.8, 1.6, 0.2],\n",
              "        [4.6, 3.2, 1.4, 0.2],\n",
              "        [5.3, 3.7, 1.5, 0.2],\n",
              "        [5. , 3.3, 1.4, 0.2],\n",
              "        [7. , 3.2, 4.7, 1.4],\n",
              "        [6.4, 3.2, 4.5, 1.5],\n",
              "        [6.9, 3.1, 4.9, 1.5],\n",
              "        [5.5, 2.3, 4. , 1.3],\n",
              "        [6.5, 2.8, 4.6, 1.5],\n",
              "        [5.7, 2.8, 4.5, 1.3],\n",
              "        [6.3, 3.3, 4.7, 1.6],\n",
              "        [4.9, 2.4, 3.3, 1. ],\n",
              "        [6.6, 2.9, 4.6, 1.3],\n",
              "        [5.2, 2.7, 3.9, 1.4],\n",
              "        [5. , 2. , 3.5, 1. ],\n",
              "        [5.9, 3. , 4.2, 1.5],\n",
              "        [6. , 2.2, 4. , 1. ],\n",
              "        [6.1, 2.9, 4.7, 1.4],\n",
              "        [5.6, 2.9, 3.6, 1.3],\n",
              "        [6.7, 3.1, 4.4, 1.4],\n",
              "        [5.6, 3. , 4.5, 1.5],\n",
              "        [5.8, 2.7, 4.1, 1. ],\n",
              "        [6.2, 2.2, 4.5, 1.5],\n",
              "        [5.6, 2.5, 3.9, 1.1],\n",
              "        [5.9, 3.2, 4.8, 1.8],\n",
              "        [6.1, 2.8, 4. , 1.3],\n",
              "        [6.3, 2.5, 4.9, 1.5],\n",
              "        [6.1, 2.8, 4.7, 1.2],\n",
              "        [6.4, 2.9, 4.3, 1.3],\n",
              "        [6.6, 3. , 4.4, 1.4],\n",
              "        [6.8, 2.8, 4.8, 1.4],\n",
              "        [6.7, 3. , 5. , 1.7],\n",
              "        [6. , 2.9, 4.5, 1.5],\n",
              "        [5.7, 2.6, 3.5, 1. ],\n",
              "        [5.5, 2.4, 3.8, 1.1],\n",
              "        [5.5, 2.4, 3.7, 1. ],\n",
              "        [5.8, 2.7, 3.9, 1.2],\n",
              "        [6. , 2.7, 5.1, 1.6],\n",
              "        [5.4, 3. , 4.5, 1.5],\n",
              "        [6. , 3.4, 4.5, 1.6],\n",
              "        [6.7, 3.1, 4.7, 1.5],\n",
              "        [6.3, 2.3, 4.4, 1.3],\n",
              "        [5.6, 3. , 4.1, 1.3],\n",
              "        [5.5, 2.5, 4. , 1.3],\n",
              "        [5.5, 2.6, 4.4, 1.2],\n",
              "        [6.1, 3. , 4.6, 1.4],\n",
              "        [5.8, 2.6, 4. , 1.2],\n",
              "        [5. , 2.3, 3.3, 1. ],\n",
              "        [5.6, 2.7, 4.2, 1.3],\n",
              "        [5.7, 3. , 4.2, 1.2],\n",
              "        [5.7, 2.9, 4.2, 1.3],\n",
              "        [6.2, 2.9, 4.3, 1.3],\n",
              "        [5.1, 2.5, 3. , 1.1],\n",
              "        [5.7, 2.8, 4.1, 1.3],\n",
              "        [6.3, 3.3, 6. , 2.5],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [7.1, 3. , 5.9, 2.1],\n",
              "        [6.3, 2.9, 5.6, 1.8],\n",
              "        [6.5, 3. , 5.8, 2.2],\n",
              "        [7.6, 3. , 6.6, 2.1],\n",
              "        [4.9, 2.5, 4.5, 1.7],\n",
              "        [7.3, 2.9, 6.3, 1.8],\n",
              "        [6.7, 2.5, 5.8, 1.8],\n",
              "        [7.2, 3.6, 6.1, 2.5],\n",
              "        [6.5, 3.2, 5.1, 2. ],\n",
              "        [6.4, 2.7, 5.3, 1.9],\n",
              "        [6.8, 3. , 5.5, 2.1],\n",
              "        [5.7, 2.5, 5. , 2. ],\n",
              "        [5.8, 2.8, 5.1, 2.4],\n",
              "        [6.4, 3.2, 5.3, 2.3],\n",
              "        [6.5, 3. , 5.5, 1.8],\n",
              "        [7.7, 3.8, 6.7, 2.2],\n",
              "        [7.7, 2.6, 6.9, 2.3],\n",
              "        [6. , 2.2, 5. , 1.5],\n",
              "        [6.9, 3.2, 5.7, 2.3],\n",
              "        [5.6, 2.8, 4.9, 2. ],\n",
              "        [7.7, 2.8, 6.7, 2. ],\n",
              "        [6.3, 2.7, 4.9, 1.8],\n",
              "        [6.7, 3.3, 5.7, 2.1],\n",
              "        [7.2, 3.2, 6. , 1.8],\n",
              "        [6.2, 2.8, 4.8, 1.8],\n",
              "        [6.1, 3. , 4.9, 1.8],\n",
              "        [6.4, 2.8, 5.6, 2.1],\n",
              "        [7.2, 3. , 5.8, 1.6],\n",
              "        [7.4, 2.8, 6.1, 1.9],\n",
              "        [7.9, 3.8, 6.4, 2. ],\n",
              "        [6.4, 2.8, 5.6, 2.2],\n",
              "        [6.3, 2.8, 5.1, 1.5],\n",
              "        [6.1, 2.6, 5.6, 1.4],\n",
              "        [7.7, 3. , 6.1, 2.3],\n",
              "        [6.3, 3.4, 5.6, 2.4],\n",
              "        [6.4, 3.1, 5.5, 1.8],\n",
              "        [6. , 3. , 4.8, 1.8],\n",
              "        [6.9, 3.1, 5.4, 2.1],\n",
              "        [6.7, 3.1, 5.6, 2.4],\n",
              "        [6.9, 3.1, 5.1, 2.3],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [6.8, 3.2, 5.9, 2.3],\n",
              "        [6.7, 3.3, 5.7, 2.5],\n",
              "        [6.7, 3. , 5.2, 2.3],\n",
              "        [6.3, 2.5, 5. , 1.9],\n",
              "        [6.5, 3. , 5.2, 2. ],\n",
              "        [6.2, 3.4, 5.4, 2.3],\n",
              "        [5.9, 3. , 5.1, 1.8]]),\n",
              " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
              " 'frame': None,\n",
              " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
              " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 150 (50 in each of three classes)\\n:Number of Attributes: 4 numeric, predictive attributes and the class\\n:Attribute Information:\\n    - sepal length in cm\\n    - sepal width in cm\\n    - petal length in cm\\n    - petal width in cm\\n    - class:\\n            - Iris-Setosa\\n            - Iris-Versicolour\\n            - Iris-Virginica\\n\\n:Summary Statistics:\\n\\n============== ==== ==== ======= ===== ====================\\n                Min  Max   Mean    SD   Class Correlation\\n============== ==== ==== ======= ===== ====================\\nsepal length:   4.3  7.9   5.84   0.83    0.7826\\nsepal width:    2.0  4.4   3.05   0.43   -0.4194\\npetal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\npetal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n============== ==== ==== ======= ===== ====================\\n\\n:Missing Attribute Values: None\\n:Class Distribution: 33.3% for each of 3 classes.\\n:Creator: R.A. Fisher\\n:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n:Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. dropdown:: References\\n\\n  - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n    Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n    Mathematical Statistics\" (John Wiley, NY, 1950).\\n  - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n    (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n  - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n    Structure and Classification Rule for Recognition in Partially Exposed\\n    Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n    Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n  - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n    on Information Theory, May 1972, 431-433.\\n  - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n    conceptual clustering system finds 3 classes in the data.\\n  - Many, many more ...\\n',\n",
              " 'feature_names': ['sepal length (cm)',\n",
              "  'sepal width (cm)',\n",
              "  'petal length (cm)',\n",
              "  'petal width (cm)'],\n",
              " 'filename': 'iris.csv',\n",
              " 'data_module': 'sklearn.datasets.data'}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJgcTGp9G8mk",
        "outputId": "93513bc7-898c-4843-8cec-1fd2138ff68e"
      },
      "source": [
        "# датасет\n",
        "X = iris.data[50:,:] # забираем данные из датасета\n",
        "y = iris.target[50:]\n",
        "X,y"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[7. , 3.2, 4.7, 1.4],\n",
              "        [6.4, 3.2, 4.5, 1.5],\n",
              "        [6.9, 3.1, 4.9, 1.5],\n",
              "        [5.5, 2.3, 4. , 1.3],\n",
              "        [6.5, 2.8, 4.6, 1.5],\n",
              "        [5.7, 2.8, 4.5, 1.3],\n",
              "        [6.3, 3.3, 4.7, 1.6],\n",
              "        [4.9, 2.4, 3.3, 1. ],\n",
              "        [6.6, 2.9, 4.6, 1.3],\n",
              "        [5.2, 2.7, 3.9, 1.4],\n",
              "        [5. , 2. , 3.5, 1. ],\n",
              "        [5.9, 3. , 4.2, 1.5],\n",
              "        [6. , 2.2, 4. , 1. ],\n",
              "        [6.1, 2.9, 4.7, 1.4],\n",
              "        [5.6, 2.9, 3.6, 1.3],\n",
              "        [6.7, 3.1, 4.4, 1.4],\n",
              "        [5.6, 3. , 4.5, 1.5],\n",
              "        [5.8, 2.7, 4.1, 1. ],\n",
              "        [6.2, 2.2, 4.5, 1.5],\n",
              "        [5.6, 2.5, 3.9, 1.1],\n",
              "        [5.9, 3.2, 4.8, 1.8],\n",
              "        [6.1, 2.8, 4. , 1.3],\n",
              "        [6.3, 2.5, 4.9, 1.5],\n",
              "        [6.1, 2.8, 4.7, 1.2],\n",
              "        [6.4, 2.9, 4.3, 1.3],\n",
              "        [6.6, 3. , 4.4, 1.4],\n",
              "        [6.8, 2.8, 4.8, 1.4],\n",
              "        [6.7, 3. , 5. , 1.7],\n",
              "        [6. , 2.9, 4.5, 1.5],\n",
              "        [5.7, 2.6, 3.5, 1. ],\n",
              "        [5.5, 2.4, 3.8, 1.1],\n",
              "        [5.5, 2.4, 3.7, 1. ],\n",
              "        [5.8, 2.7, 3.9, 1.2],\n",
              "        [6. , 2.7, 5.1, 1.6],\n",
              "        [5.4, 3. , 4.5, 1.5],\n",
              "        [6. , 3.4, 4.5, 1.6],\n",
              "        [6.7, 3.1, 4.7, 1.5],\n",
              "        [6.3, 2.3, 4.4, 1.3],\n",
              "        [5.6, 3. , 4.1, 1.3],\n",
              "        [5.5, 2.5, 4. , 1.3],\n",
              "        [5.5, 2.6, 4.4, 1.2],\n",
              "        [6.1, 3. , 4.6, 1.4],\n",
              "        [5.8, 2.6, 4. , 1.2],\n",
              "        [5. , 2.3, 3.3, 1. ],\n",
              "        [5.6, 2.7, 4.2, 1.3],\n",
              "        [5.7, 3. , 4.2, 1.2],\n",
              "        [5.7, 2.9, 4.2, 1.3],\n",
              "        [6.2, 2.9, 4.3, 1.3],\n",
              "        [5.1, 2.5, 3. , 1.1],\n",
              "        [5.7, 2.8, 4.1, 1.3],\n",
              "        [6.3, 3.3, 6. , 2.5],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [7.1, 3. , 5.9, 2.1],\n",
              "        [6.3, 2.9, 5.6, 1.8],\n",
              "        [6.5, 3. , 5.8, 2.2],\n",
              "        [7.6, 3. , 6.6, 2.1],\n",
              "        [4.9, 2.5, 4.5, 1.7],\n",
              "        [7.3, 2.9, 6.3, 1.8],\n",
              "        [6.7, 2.5, 5.8, 1.8],\n",
              "        [7.2, 3.6, 6.1, 2.5],\n",
              "        [6.5, 3.2, 5.1, 2. ],\n",
              "        [6.4, 2.7, 5.3, 1.9],\n",
              "        [6.8, 3. , 5.5, 2.1],\n",
              "        [5.7, 2.5, 5. , 2. ],\n",
              "        [5.8, 2.8, 5.1, 2.4],\n",
              "        [6.4, 3.2, 5.3, 2.3],\n",
              "        [6.5, 3. , 5.5, 1.8],\n",
              "        [7.7, 3.8, 6.7, 2.2],\n",
              "        [7.7, 2.6, 6.9, 2.3],\n",
              "        [6. , 2.2, 5. , 1.5],\n",
              "        [6.9, 3.2, 5.7, 2.3],\n",
              "        [5.6, 2.8, 4.9, 2. ],\n",
              "        [7.7, 2.8, 6.7, 2. ],\n",
              "        [6.3, 2.7, 4.9, 1.8],\n",
              "        [6.7, 3.3, 5.7, 2.1],\n",
              "        [7.2, 3.2, 6. , 1.8],\n",
              "        [6.2, 2.8, 4.8, 1.8],\n",
              "        [6.1, 3. , 4.9, 1.8],\n",
              "        [6.4, 2.8, 5.6, 2.1],\n",
              "        [7.2, 3. , 5.8, 1.6],\n",
              "        [7.4, 2.8, 6.1, 1.9],\n",
              "        [7.9, 3.8, 6.4, 2. ],\n",
              "        [6.4, 2.8, 5.6, 2.2],\n",
              "        [6.3, 2.8, 5.1, 1.5],\n",
              "        [6.1, 2.6, 5.6, 1.4],\n",
              "        [7.7, 3. , 6.1, 2.3],\n",
              "        [6.3, 3.4, 5.6, 2.4],\n",
              "        [6.4, 3.1, 5.5, 1.8],\n",
              "        [6. , 3. , 4.8, 1.8],\n",
              "        [6.9, 3.1, 5.4, 2.1],\n",
              "        [6.7, 3.1, 5.6, 2.4],\n",
              "        [6.9, 3.1, 5.1, 2.3],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [6.8, 3.2, 5.9, 2.3],\n",
              "        [6.7, 3.3, 5.7, 2.5],\n",
              "        [6.7, 3. , 5.2, 2.3],\n",
              "        [6.3, 2.5, 5. , 1.9],\n",
              "        [6.5, 3. , 5.2, 2. ],\n",
              "        [6.2, 3.4, 5.4, 2.3],\n",
              "        [5.9, 3. , 5.1, 1.8]]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.where(y == 1, 1, 0)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_0c7XVsMC7g",
        "outputId": "0d4eb2c4-cc5e-4368-b3db-cb8b26b57d6e"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.c_[np.ones(len(X)), X]\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbjSNAlVYboi",
        "outputId": "1f0dd6ee-7cbd-4e04-f2ef-0c7047eb6047"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1. , 7. , 3.2, 4.7, 1.4],\n",
              "       [1. , 6.4, 3.2, 4.5, 1.5],\n",
              "       [1. , 6.9, 3.1, 4.9, 1.5],\n",
              "       [1. , 5.5, 2.3, 4. , 1.3],\n",
              "       [1. , 6.5, 2.8, 4.6, 1.5],\n",
              "       [1. , 5.7, 2.8, 4.5, 1.3],\n",
              "       [1. , 6.3, 3.3, 4.7, 1.6],\n",
              "       [1. , 4.9, 2.4, 3.3, 1. ],\n",
              "       [1. , 6.6, 2.9, 4.6, 1.3],\n",
              "       [1. , 5.2, 2.7, 3.9, 1.4],\n",
              "       [1. , 5. , 2. , 3.5, 1. ],\n",
              "       [1. , 5.9, 3. , 4.2, 1.5],\n",
              "       [1. , 6. , 2.2, 4. , 1. ],\n",
              "       [1. , 6.1, 2.9, 4.7, 1.4],\n",
              "       [1. , 5.6, 2.9, 3.6, 1.3],\n",
              "       [1. , 6.7, 3.1, 4.4, 1.4],\n",
              "       [1. , 5.6, 3. , 4.5, 1.5],\n",
              "       [1. , 5.8, 2.7, 4.1, 1. ],\n",
              "       [1. , 6.2, 2.2, 4.5, 1.5],\n",
              "       [1. , 5.6, 2.5, 3.9, 1.1],\n",
              "       [1. , 5.9, 3.2, 4.8, 1.8],\n",
              "       [1. , 6.1, 2.8, 4. , 1.3],\n",
              "       [1. , 6.3, 2.5, 4.9, 1.5],\n",
              "       [1. , 6.1, 2.8, 4.7, 1.2],\n",
              "       [1. , 6.4, 2.9, 4.3, 1.3],\n",
              "       [1. , 6.6, 3. , 4.4, 1.4],\n",
              "       [1. , 6.8, 2.8, 4.8, 1.4],\n",
              "       [1. , 6.7, 3. , 5. , 1.7],\n",
              "       [1. , 6. , 2.9, 4.5, 1.5],\n",
              "       [1. , 5.7, 2.6, 3.5, 1. ],\n",
              "       [1. , 5.5, 2.4, 3.8, 1.1],\n",
              "       [1. , 5.5, 2.4, 3.7, 1. ],\n",
              "       [1. , 5.8, 2.7, 3.9, 1.2],\n",
              "       [1. , 6. , 2.7, 5.1, 1.6],\n",
              "       [1. , 5.4, 3. , 4.5, 1.5],\n",
              "       [1. , 6. , 3.4, 4.5, 1.6],\n",
              "       [1. , 6.7, 3.1, 4.7, 1.5],\n",
              "       [1. , 6.3, 2.3, 4.4, 1.3],\n",
              "       [1. , 5.6, 3. , 4.1, 1.3],\n",
              "       [1. , 5.5, 2.5, 4. , 1.3],\n",
              "       [1. , 5.5, 2.6, 4.4, 1.2],\n",
              "       [1. , 6.1, 3. , 4.6, 1.4],\n",
              "       [1. , 5.8, 2.6, 4. , 1.2],\n",
              "       [1. , 5. , 2.3, 3.3, 1. ],\n",
              "       [1. , 5.6, 2.7, 4.2, 1.3],\n",
              "       [1. , 5.7, 3. , 4.2, 1.2],\n",
              "       [1. , 5.7, 2.9, 4.2, 1.3],\n",
              "       [1. , 6.2, 2.9, 4.3, 1.3],\n",
              "       [1. , 5.1, 2.5, 3. , 1.1],\n",
              "       [1. , 5.7, 2.8, 4.1, 1.3],\n",
              "       [1. , 6.3, 3.3, 6. , 2.5],\n",
              "       [1. , 5.8, 2.7, 5.1, 1.9],\n",
              "       [1. , 7.1, 3. , 5.9, 2.1],\n",
              "       [1. , 6.3, 2.9, 5.6, 1.8],\n",
              "       [1. , 6.5, 3. , 5.8, 2.2],\n",
              "       [1. , 7.6, 3. , 6.6, 2.1],\n",
              "       [1. , 4.9, 2.5, 4.5, 1.7],\n",
              "       [1. , 7.3, 2.9, 6.3, 1.8],\n",
              "       [1. , 6.7, 2.5, 5.8, 1.8],\n",
              "       [1. , 7.2, 3.6, 6.1, 2.5],\n",
              "       [1. , 6.5, 3.2, 5.1, 2. ],\n",
              "       [1. , 6.4, 2.7, 5.3, 1.9],\n",
              "       [1. , 6.8, 3. , 5.5, 2.1],\n",
              "       [1. , 5.7, 2.5, 5. , 2. ],\n",
              "       [1. , 5.8, 2.8, 5.1, 2.4],\n",
              "       [1. , 6.4, 3.2, 5.3, 2.3],\n",
              "       [1. , 6.5, 3. , 5.5, 1.8],\n",
              "       [1. , 7.7, 3.8, 6.7, 2.2],\n",
              "       [1. , 7.7, 2.6, 6.9, 2.3],\n",
              "       [1. , 6. , 2.2, 5. , 1.5],\n",
              "       [1. , 6.9, 3.2, 5.7, 2.3],\n",
              "       [1. , 5.6, 2.8, 4.9, 2. ],\n",
              "       [1. , 7.7, 2.8, 6.7, 2. ],\n",
              "       [1. , 6.3, 2.7, 4.9, 1.8],\n",
              "       [1. , 6.7, 3.3, 5.7, 2.1],\n",
              "       [1. , 7.2, 3.2, 6. , 1.8],\n",
              "       [1. , 6.2, 2.8, 4.8, 1.8],\n",
              "       [1. , 6.1, 3. , 4.9, 1.8],\n",
              "       [1. , 6.4, 2.8, 5.6, 2.1],\n",
              "       [1. , 7.2, 3. , 5.8, 1.6],\n",
              "       [1. , 7.4, 2.8, 6.1, 1.9],\n",
              "       [1. , 7.9, 3.8, 6.4, 2. ],\n",
              "       [1. , 6.4, 2.8, 5.6, 2.2],\n",
              "       [1. , 6.3, 2.8, 5.1, 1.5],\n",
              "       [1. , 6.1, 2.6, 5.6, 1.4],\n",
              "       [1. , 7.7, 3. , 6.1, 2.3],\n",
              "       [1. , 6.3, 3.4, 5.6, 2.4],\n",
              "       [1. , 6.4, 3.1, 5.5, 1.8],\n",
              "       [1. , 6. , 3. , 4.8, 1.8],\n",
              "       [1. , 6.9, 3.1, 5.4, 2.1],\n",
              "       [1. , 6.7, 3.1, 5.6, 2.4],\n",
              "       [1. , 6.9, 3.1, 5.1, 2.3],\n",
              "       [1. , 5.8, 2.7, 5.1, 1.9],\n",
              "       [1. , 6.8, 3.2, 5.9, 2.3],\n",
              "       [1. , 6.7, 3.3, 5.7, 2.5],\n",
              "       [1. , 6.7, 3. , 5.2, 2.3],\n",
              "       [1. , 6.3, 2.5, 5. , 1.9],\n",
              "       [1. , 6.5, 3. , 5.2, 2. ],\n",
              "       [1. , 6.2, 3.4, 5.4, 2.3],\n",
              "       [1. , 5.9, 3. , 5.1, 1.8]])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Масштабируем наши признаки"
      ],
      "metadata": {
        "id": "EX0K5MgCVD8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  scaler = StandardScaler()\n",
        "  X = scaler.fit_transform(X)\n",
        "  X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iv_VIjQ3xqbC",
        "outputId": "92a2288f-adac-49bb-9c32-8768010ff0b0"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  1.11900931,  0.99068792, -0.25077906,\n",
              "        -0.65303909],\n",
              "       [ 0.        ,  0.        ,  0.20924564,  0.99068792, -0.49425387,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        ,  0.96738203,  0.68864892, -0.00730424,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        , -1.15539985, -1.72766308, -1.10294091,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        ,  0.36087292, -0.21746808, -0.37251647,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        , -0.8521453 , -0.21746808, -0.49425387,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        ,  0.05761837,  1.29272692, -0.25077906,\n",
              "        -0.17982236],\n",
              "       [ 0.        ,  0.        , -2.06516352, -1.42562408, -1.95510276,\n",
              "        -1.59947255],\n",
              "       [ 0.        ,  0.        ,  0.5125002 ,  0.08457092, -0.37251647,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        , -1.61028169, -0.51950708, -1.22467832,\n",
              "        -0.65303909],\n",
              "       [ 0.        ,  0.        , -1.91353624, -2.63378009, -1.71162795,\n",
              "        -1.59947255],\n",
              "       [ 0.        ,  0.        , -0.54889074,  0.38660992, -0.8594661 ,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        , -0.39726347, -2.02970209, -1.10294091,\n",
              "        -1.59947255],\n",
              "       [ 0.        ,  0.        , -0.24563619,  0.08457092, -0.25077906,\n",
              "        -0.65303909],\n",
              "       [ 0.        ,  0.        , -1.00377258,  0.08457092, -1.58989054,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        ,  0.66412748,  0.68864892, -0.61599128,\n",
              "        -0.65303909],\n",
              "       [ 0.        ,  0.        , -1.00377258,  0.38660992, -0.49425387,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        , -0.70051802, -0.51950708, -0.9812035 ,\n",
              "        -1.59947255],\n",
              "       [ 0.        ,  0.        , -0.09400891, -2.02970209, -0.49425387,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        , -1.00377258, -1.12358508, -1.22467832,\n",
              "        -1.36286418],\n",
              "       [ 0.        ,  0.        , -0.54889074,  0.99068792, -0.12904165,\n",
              "         0.29339437],\n",
              "       [ 0.        ,  0.        , -0.24563619, -0.21746808, -1.10294091,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        ,  0.05761837, -1.12358508, -0.00730424,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        , -0.24563619, -0.21746808, -0.25077906,\n",
              "        -1.12625582],\n",
              "       [ 0.        ,  0.        ,  0.20924564,  0.08457092, -0.73772869,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        ,  0.5125002 ,  0.38660992, -0.61599128,\n",
              "        -0.65303909],\n",
              "       [ 0.        ,  0.        ,  0.81575475, -0.21746808, -0.12904165,\n",
              "        -0.65303909],\n",
              "       [ 0.        ,  0.        ,  0.66412748,  0.38660992,  0.11443316,\n",
              "         0.05678601],\n",
              "       [ 0.        ,  0.        , -0.39726347,  0.08457092, -0.49425387,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        , -0.8521453 , -0.82154608, -1.71162795,\n",
              "        -1.59947255],\n",
              "       [ 0.        ,  0.        , -1.15539985, -1.42562408, -1.34641572,\n",
              "        -1.36286418],\n",
              "       [ 0.        ,  0.        , -1.15539985, -1.42562408, -1.46815313,\n",
              "        -1.59947255],\n",
              "       [ 0.        ,  0.        , -0.70051802, -0.51950708, -1.22467832,\n",
              "        -1.12625582],\n",
              "       [ 0.        ,  0.        , -0.39726347, -0.51950708,  0.23617057,\n",
              "        -0.17982236],\n",
              "       [ 0.        ,  0.        , -1.30702713,  0.38660992, -0.49425387,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        , -0.39726347,  1.59476592, -0.49425387,\n",
              "        -0.17982236],\n",
              "       [ 0.        ,  0.        ,  0.66412748,  0.68864892, -0.25077906,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        ,  0.05761837, -1.72766308, -0.61599128,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        , -1.00377258,  0.38660992, -0.9812035 ,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        , -1.15539985, -1.12358508, -1.10294091,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        , -1.15539985, -0.82154608, -0.61599128,\n",
              "        -1.12625582],\n",
              "       [ 0.        ,  0.        , -0.24563619,  0.38660992, -0.37251647,\n",
              "        -0.65303909],\n",
              "       [ 0.        ,  0.        , -0.70051802, -0.82154608, -1.10294091,\n",
              "        -1.12625582],\n",
              "       [ 0.        ,  0.        , -1.91353624, -1.72766308, -1.95510276,\n",
              "        -1.59947255],\n",
              "       [ 0.        ,  0.        , -1.00377258, -0.51950708, -0.8594661 ,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        , -0.8521453 ,  0.38660992, -0.8594661 ,\n",
              "        -1.12625582],\n",
              "       [ 0.        ,  0.        , -0.8521453 ,  0.08457092, -0.8594661 ,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        , -0.09400891,  0.08457092, -0.73772869,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        , -1.76190896, -1.12358508, -2.32031498,\n",
              "        -1.36286418],\n",
              "       [ 0.        ,  0.        , -0.8521453 , -0.21746808, -0.9812035 ,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        ,  0.05761837,  1.29272692,  1.33180724,\n",
              "         1.94965293],\n",
              "       [ 0.        ,  0.        , -0.70051802, -0.51950708,  0.23617057,\n",
              "         0.53000274],\n",
              "       [ 0.        ,  0.        ,  1.27063658,  0.38660992,  1.21006983,\n",
              "         1.00321947],\n",
              "       [ 0.        ,  0.        ,  0.05761837,  0.08457092,  0.84485761,\n",
              "         0.29339437],\n",
              "       [ 0.        ,  0.        ,  0.36087292,  0.38660992,  1.08833242,\n",
              "         1.23982783],\n",
              "       [ 0.        ,  0.        ,  2.02877297,  0.38660992,  2.06223168,\n",
              "         1.00321947],\n",
              "       [ 0.        ,  0.        , -2.06516352, -1.12358508, -0.49425387,\n",
              "         0.05678601],\n",
              "       [ 0.        ,  0.        ,  1.57389114,  0.08457092,  1.69701946,\n",
              "         0.29339437],\n",
              "       [ 0.        ,  0.        ,  0.66412748, -1.12358508,  1.08833242,\n",
              "         0.29339437],\n",
              "       [ 0.        ,  0.        ,  1.42226386,  2.19884393,  1.45354464,\n",
              "         1.94965293],\n",
              "       [ 0.        ,  0.        ,  0.36087292,  0.99068792,  0.23617057,\n",
              "         0.7666111 ],\n",
              "       [ 0.        ,  0.        ,  0.20924564, -0.51950708,  0.47964538,\n",
              "         0.53000274],\n",
              "       [ 0.        ,  0.        ,  0.81575475,  0.38660992,  0.7231202 ,\n",
              "         1.00321947],\n",
              "       [ 0.        ,  0.        , -0.8521453 , -1.12358508,  0.11443316,\n",
              "         0.7666111 ],\n",
              "       [ 0.        ,  0.        , -0.70051802, -0.21746808,  0.23617057,\n",
              "         1.71304456],\n",
              "       [ 0.        ,  0.        ,  0.20924564,  0.99068792,  0.47964538,\n",
              "         1.4764362 ],\n",
              "       [ 0.        ,  0.        ,  0.36087292,  0.38660992,  0.7231202 ,\n",
              "         0.29339437],\n",
              "       [ 0.        ,  0.        ,  2.18040025,  2.80292193,  2.18396909,\n",
              "         1.23982783],\n",
              "       [ 0.        ,  0.        ,  2.18040025, -0.82154608,  2.4274439 ,\n",
              "         1.4764362 ],\n",
              "       [ 0.        ,  0.        , -0.39726347, -2.02970209,  0.11443316,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        ,  0.96738203,  0.99068792,  0.96659501,\n",
              "         1.4764362 ],\n",
              "       [ 0.        ,  0.        , -1.00377258, -0.21746808, -0.00730424,\n",
              "         0.7666111 ],\n",
              "       [ 0.        ,  0.        ,  2.18040025, -0.21746808,  2.18396909,\n",
              "         0.7666111 ],\n",
              "       [ 0.        ,  0.        ,  0.05761837, -0.51950708, -0.00730424,\n",
              "         0.29339437],\n",
              "       [ 0.        ,  0.        ,  0.66412748,  1.29272692,  0.96659501,\n",
              "         1.00321947],\n",
              "       [ 0.        ,  0.        ,  1.42226386,  0.99068792,  1.33180724,\n",
              "         0.29339437],\n",
              "       [ 0.        ,  0.        , -0.09400891, -0.21746808, -0.12904165,\n",
              "         0.29339437],\n",
              "       [ 0.        ,  0.        , -0.24563619,  0.38660992, -0.00730424,\n",
              "         0.29339437],\n",
              "       [ 0.        ,  0.        ,  0.20924564, -0.21746808,  0.84485761,\n",
              "         1.00321947],\n",
              "       [ 0.        ,  0.        ,  1.42226386,  0.38660992,  1.08833242,\n",
              "        -0.17982236],\n",
              "       [ 0.        ,  0.        ,  1.72551842, -0.21746808,  1.45354464,\n",
              "         0.53000274],\n",
              "       [ 0.        ,  0.        ,  2.4836548 ,  2.80292193,  1.81875686,\n",
              "         0.7666111 ],\n",
              "       [ 0.        ,  0.        ,  0.20924564, -0.21746808,  0.84485761,\n",
              "         1.23982783],\n",
              "       [ 0.        ,  0.        ,  0.05761837, -0.21746808,  0.23617057,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        , -0.24563619, -0.82154608,  0.84485761,\n",
              "        -0.65303909],\n",
              "       [ 0.        ,  0.        ,  2.18040025,  0.38660992,  1.45354464,\n",
              "         1.4764362 ],\n",
              "       [ 0.        ,  0.        ,  0.05761837,  1.59476592,  0.84485761,\n",
              "         1.71304456],\n",
              "       [ 0.        ,  0.        ,  0.20924564,  0.68864892,  0.7231202 ,\n",
              "         0.29339437],\n",
              "       [ 0.        ,  0.        , -0.39726347,  0.38660992, -0.12904165,\n",
              "         0.29339437],\n",
              "       [ 0.        ,  0.        ,  0.96738203,  0.68864892,  0.60138279,\n",
              "         1.00321947],\n",
              "       [ 0.        ,  0.        ,  0.66412748,  0.68864892,  0.84485761,\n",
              "         1.71304456],\n",
              "       [ 0.        ,  0.        ,  0.96738203,  0.68864892,  0.23617057,\n",
              "         1.4764362 ],\n",
              "       [ 0.        ,  0.        , -0.70051802, -0.51950708,  0.23617057,\n",
              "         0.53000274],\n",
              "       [ 0.        ,  0.        ,  0.81575475,  0.99068792,  1.21006983,\n",
              "         1.4764362 ],\n",
              "       [ 0.        ,  0.        ,  0.66412748,  1.29272692,  0.96659501,\n",
              "         1.94965293],\n",
              "       [ 0.        ,  0.        ,  0.66412748,  0.38660992,  0.35790798,\n",
              "         1.4764362 ],\n",
              "       [ 0.        ,  0.        ,  0.05761837, -1.12358508,  0.11443316,\n",
              "         0.53000274],\n",
              "       [ 0.        ,  0.        ,  0.36087292,  0.38660992,  0.35790798,\n",
              "         0.7666111 ],\n",
              "       [ 0.        ,  0.        , -0.09400891,  1.59476592,  0.60138279,\n",
              "         1.4764362 ],\n",
              "       [ 0.        ,  0.        , -0.54889074,  0.38660992,  0.23617057,\n",
              "         0.29339437]])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализуем функцию:\n",
        "\n",
        "logloss - функция логистической функции потерь (cross entropy)  logloss=−1n∑(yi⋅log(pi)+(1−yi)⋅log(1−pi))\n",
        "gr_logloss - градиент функции logloss записанные в матричном виде.  XT(σ(XW)−Y)"
      ],
      "metadata": {
        "id": "1pRk9oVw82YV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzbVvH7DG8ml"
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def logloss(y, y_proba):\n",
        "    logloss_1 = np.sum(np.log(y_proba[y == 1] + 1e-30))\n",
        "    logloss_0 = np.sum(np.log(1 - y_proba[y == 0] + 1e-30))\n",
        "    logloss_total = -(logloss_0 + logloss_1) / len(y)\n",
        "    return logloss_total\n",
        "\n",
        "\n",
        "def gr_logloss(X, W, y):\n",
        "    y_proba = sigmoid(X @ W)\n",
        "    grad = X.T @ (y_proba - y)\n",
        "    return grad"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучим логистическую регрессию при помощи градиентного спуска."
      ],
      "metadata": {
        "id": "Z-9VfsPkVi3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# установка минимального значения, на которое должны изменяться веса\n",
        "eps = 0.0001\n",
        "\n",
        "# первоначальное точка\n",
        "#np.random.seed(2)\n",
        "W = np.random.randn(X.shape[1])\n",
        "W = np.where(W == 1, 1, 1)\n",
        "\n",
        "# размер шага (learning rate)\n",
        "learning_rate = 0.01\n",
        "\n",
        "next_W = W\n",
        "\n",
        "# количество итераций\n",
        "n = 70\n",
        "for i in range(n):\n",
        "    cur_W = next_W\n",
        "\n",
        "    # движение в негативную сторону вычисляемого градиента\n",
        "    next_W = cur_W - learning_rate * gr_logloss(X, cur_W, y)\n",
        "\n",
        "    # остановка когда достигнута необходимая степень точности\n",
        "    if np.linalg.norm(cur_W - next_W) <= eps:\n",
        "        break\n",
        "\n",
        "    if i % 1 == 0:\n",
        "        print(f\"Итерация: {i}\")\n",
        "        y_proba = sigmoid(X @ next_W)\n",
        "        y_class = np.where(y_proba >= 0.5, 1, 0)\n",
        "        accuracy = (y_class == y).sum() / len(y)\n",
        "        print(f\"Logloss {logloss(y, y_proba)}\")\n",
        "        print(f\"Accuracy {accuracy}\")\n",
        "        print(\"--------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rHINxwdYy1E",
        "outputId": "2bed461d-d2be-4923-c317-c178d70e8470"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Итерация: 0\n",
            "Logloss 1.2910308882282424\n",
            "Accuracy 0.22\n",
            "--------------------------------------------------------\n",
            "Итерация: 1\n",
            "Logloss 0.47971328600027185\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 2\n",
            "Logloss 0.33937215184892267\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 3\n",
            "Logloss 0.29230496367120734\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 4\n",
            "Logloss 0.26469821673069044\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 5\n",
            "Logloss 0.2452868216750972\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 6\n",
            "Logloss 0.23036939240585455\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 7\n",
            "Logloss 0.21829776410980814\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 8\n",
            "Logloss 0.20819857415842297\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 9\n",
            "Logloss 0.19955260272363154\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 10\n",
            "Logloss 0.19202481974068022\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 11\n",
            "Logloss 0.1853854621575023\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 12\n",
            "Logloss 0.1794694315592929\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 13\n",
            "Logloss 0.17415368228465133\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 14\n",
            "Logloss 0.1693438023107212\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 15\n",
            "Logloss 0.16496562312164506\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 16\n",
            "Logloss 0.16095974040128677\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 17\n",
            "Logloss 0.15727780161023805\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 18\n",
            "Logloss 0.1538799105880311\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 19\n",
            "Logloss 0.15073276359554602\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 20\n",
            "Logloss 0.14780827919357656\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 21\n",
            "Logloss 0.145082570594238\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 22\n",
            "Logloss 0.14253516118397744\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 23\n",
            "Logloss 0.140148376346284\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 24\n",
            "Logloss 0.13790686548689618\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 25\n",
            "Logloss 0.13579722181297682\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 26\n",
            "Logloss 0.13380767659145346\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 27\n",
            "Logloss 0.13192785090639544\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 28\n",
            "Logloss 0.13014855233630654\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 29\n",
            "Logloss 0.12846160710229337\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 30\n",
            "Logloss 0.12685972049923736\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 31\n",
            "Logloss 0.1253363600790288\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 32\n",
            "Logloss 0.12388565728504648\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 33\n",
            "Logloss 0.12250232416134256\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 34\n",
            "Logloss 0.12118158246216172\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 35\n",
            "Logloss 0.11991910302630977\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 36\n",
            "Logloss 0.11871095369835444\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 37\n",
            "Logloss 0.1175535544048703\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 38\n",
            "Logloss 0.11644363825093137\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 39\n",
            "Logloss 0.11537821770602288\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 40\n",
            "Logloss 0.11435455511156153\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 41\n",
            "Logloss 0.11337013687335443\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 42\n",
            "Logloss 0.11242265080846466\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 43\n",
            "Logloss 0.11150996620234854\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 44\n",
            "Logloss 0.1106301162028342\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 45\n",
            "Logloss 0.10978128223566436\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 46\n",
            "Logloss 0.10896178017438783\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 47\n",
            "Logloss 0.10817004803728102\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 48\n",
            "Logloss 0.1074046350172436\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 49\n",
            "Logloss 0.106664191678455\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 50\n",
            "Logloss 0.10594746117697344\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 51\n",
            "Logloss 0.1052532713821904\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 52\n",
            "Logloss 0.1045805277927505\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 53\n",
            "Logloss 0.10392820715472383\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 54\n",
            "Logloss 0.10329535170189516\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 55\n",
            "Logloss 0.10268106394835018\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 56\n",
            "Logloss 0.10208450197238\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 57\n",
            "Logloss 0.10150487513832152\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 58\n",
            "Logloss 0.10094144020949346\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 59\n",
            "Logloss 0.10039349781104169\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 60\n",
            "Logloss 0.09986038920640052\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 61\n",
            "Logloss 0.09934149335532445\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 62\n",
            "Logloss 0.09883622422514043\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 63\n",
            "Logloss 0.09834402833009133\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 64\n",
            "Logloss 0.09786438247645654\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 65\n",
            "Logloss 0.09739679169360016\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 66\n",
            "Logloss 0.096940787333258\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 67\n",
            "Logloss 0.09649592532127539\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 68\n",
            "Logloss 0.09606178454768118\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 69\n",
            "Logloss 0.0956379653824586\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сравним с модеделью из коробки"
      ],
      "metadata": {
        "id": "OdI_we-yUKrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "model = LogisticRegression(max_iter=500)"
      ],
      "metadata": {
        "id": "p-_DbxeTZjxe"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.Series(data = np.ravel(y))\n",
        "X,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8dyPSiDZ-MG",
        "outputId": "43514b9a-b76e-449f-93de-090574cd93b5"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 0.        ,  1.11900931,  0.99068792, -0.25077906, -0.65303909],\n",
              "        [ 0.        ,  0.20924564,  0.99068792, -0.49425387, -0.41643072],\n",
              "        [ 0.        ,  0.96738203,  0.68864892, -0.00730424, -0.41643072],\n",
              "        [ 0.        , -1.15539985, -1.72766308, -1.10294091, -0.88964745],\n",
              "        [ 0.        ,  0.36087292, -0.21746808, -0.37251647, -0.41643072],\n",
              "        [ 0.        , -0.8521453 , -0.21746808, -0.49425387, -0.88964745],\n",
              "        [ 0.        ,  0.05761837,  1.29272692, -0.25077906, -0.17982236],\n",
              "        [ 0.        , -2.06516352, -1.42562408, -1.95510276, -1.59947255],\n",
              "        [ 0.        ,  0.5125002 ,  0.08457092, -0.37251647, -0.88964745],\n",
              "        [ 0.        , -1.61028169, -0.51950708, -1.22467832, -0.65303909],\n",
              "        [ 0.        , -1.91353624, -2.63378009, -1.71162795, -1.59947255],\n",
              "        [ 0.        , -0.54889074,  0.38660992, -0.8594661 , -0.41643072],\n",
              "        [ 0.        , -0.39726347, -2.02970209, -1.10294091, -1.59947255],\n",
              "        [ 0.        , -0.24563619,  0.08457092, -0.25077906, -0.65303909],\n",
              "        [ 0.        , -1.00377258,  0.08457092, -1.58989054, -0.88964745],\n",
              "        [ 0.        ,  0.66412748,  0.68864892, -0.61599128, -0.65303909],\n",
              "        [ 0.        , -1.00377258,  0.38660992, -0.49425387, -0.41643072],\n",
              "        [ 0.        , -0.70051802, -0.51950708, -0.9812035 , -1.59947255],\n",
              "        [ 0.        , -0.09400891, -2.02970209, -0.49425387, -0.41643072],\n",
              "        [ 0.        , -1.00377258, -1.12358508, -1.22467832, -1.36286418],\n",
              "        [ 0.        , -0.54889074,  0.99068792, -0.12904165,  0.29339437],\n",
              "        [ 0.        , -0.24563619, -0.21746808, -1.10294091, -0.88964745],\n",
              "        [ 0.        ,  0.05761837, -1.12358508, -0.00730424, -0.41643072],\n",
              "        [ 0.        , -0.24563619, -0.21746808, -0.25077906, -1.12625582],\n",
              "        [ 0.        ,  0.20924564,  0.08457092, -0.73772869, -0.88964745],\n",
              "        [ 0.        ,  0.5125002 ,  0.38660992, -0.61599128, -0.65303909],\n",
              "        [ 0.        ,  0.81575475, -0.21746808, -0.12904165, -0.65303909],\n",
              "        [ 0.        ,  0.66412748,  0.38660992,  0.11443316,  0.05678601],\n",
              "        [ 0.        , -0.39726347,  0.08457092, -0.49425387, -0.41643072],\n",
              "        [ 0.        , -0.8521453 , -0.82154608, -1.71162795, -1.59947255],\n",
              "        [ 0.        , -1.15539985, -1.42562408, -1.34641572, -1.36286418],\n",
              "        [ 0.        , -1.15539985, -1.42562408, -1.46815313, -1.59947255],\n",
              "        [ 0.        , -0.70051802, -0.51950708, -1.22467832, -1.12625582],\n",
              "        [ 0.        , -0.39726347, -0.51950708,  0.23617057, -0.17982236],\n",
              "        [ 0.        , -1.30702713,  0.38660992, -0.49425387, -0.41643072],\n",
              "        [ 0.        , -0.39726347,  1.59476592, -0.49425387, -0.17982236],\n",
              "        [ 0.        ,  0.66412748,  0.68864892, -0.25077906, -0.41643072],\n",
              "        [ 0.        ,  0.05761837, -1.72766308, -0.61599128, -0.88964745],\n",
              "        [ 0.        , -1.00377258,  0.38660992, -0.9812035 , -0.88964745],\n",
              "        [ 0.        , -1.15539985, -1.12358508, -1.10294091, -0.88964745],\n",
              "        [ 0.        , -1.15539985, -0.82154608, -0.61599128, -1.12625582],\n",
              "        [ 0.        , -0.24563619,  0.38660992, -0.37251647, -0.65303909],\n",
              "        [ 0.        , -0.70051802, -0.82154608, -1.10294091, -1.12625582],\n",
              "        [ 0.        , -1.91353624, -1.72766308, -1.95510276, -1.59947255],\n",
              "        [ 0.        , -1.00377258, -0.51950708, -0.8594661 , -0.88964745],\n",
              "        [ 0.        , -0.8521453 ,  0.38660992, -0.8594661 , -1.12625582],\n",
              "        [ 0.        , -0.8521453 ,  0.08457092, -0.8594661 , -0.88964745],\n",
              "        [ 0.        , -0.09400891,  0.08457092, -0.73772869, -0.88964745],\n",
              "        [ 0.        , -1.76190896, -1.12358508, -2.32031498, -1.36286418],\n",
              "        [ 0.        , -0.8521453 , -0.21746808, -0.9812035 , -0.88964745],\n",
              "        [ 0.        ,  0.05761837,  1.29272692,  1.33180724,  1.94965293],\n",
              "        [ 0.        , -0.70051802, -0.51950708,  0.23617057,  0.53000274],\n",
              "        [ 0.        ,  1.27063658,  0.38660992,  1.21006983,  1.00321947],\n",
              "        [ 0.        ,  0.05761837,  0.08457092,  0.84485761,  0.29339437],\n",
              "        [ 0.        ,  0.36087292,  0.38660992,  1.08833242,  1.23982783],\n",
              "        [ 0.        ,  2.02877297,  0.38660992,  2.06223168,  1.00321947],\n",
              "        [ 0.        , -2.06516352, -1.12358508, -0.49425387,  0.05678601],\n",
              "        [ 0.        ,  1.57389114,  0.08457092,  1.69701946,  0.29339437],\n",
              "        [ 0.        ,  0.66412748, -1.12358508,  1.08833242,  0.29339437],\n",
              "        [ 0.        ,  1.42226386,  2.19884393,  1.45354464,  1.94965293],\n",
              "        [ 0.        ,  0.36087292,  0.99068792,  0.23617057,  0.7666111 ],\n",
              "        [ 0.        ,  0.20924564, -0.51950708,  0.47964538,  0.53000274],\n",
              "        [ 0.        ,  0.81575475,  0.38660992,  0.7231202 ,  1.00321947],\n",
              "        [ 0.        , -0.8521453 , -1.12358508,  0.11443316,  0.7666111 ],\n",
              "        [ 0.        , -0.70051802, -0.21746808,  0.23617057,  1.71304456],\n",
              "        [ 0.        ,  0.20924564,  0.99068792,  0.47964538,  1.4764362 ],\n",
              "        [ 0.        ,  0.36087292,  0.38660992,  0.7231202 ,  0.29339437],\n",
              "        [ 0.        ,  2.18040025,  2.80292193,  2.18396909,  1.23982783],\n",
              "        [ 0.        ,  2.18040025, -0.82154608,  2.4274439 ,  1.4764362 ],\n",
              "        [ 0.        , -0.39726347, -2.02970209,  0.11443316, -0.41643072],\n",
              "        [ 0.        ,  0.96738203,  0.99068792,  0.96659501,  1.4764362 ],\n",
              "        [ 0.        , -1.00377258, -0.21746808, -0.00730424,  0.7666111 ],\n",
              "        [ 0.        ,  2.18040025, -0.21746808,  2.18396909,  0.7666111 ],\n",
              "        [ 0.        ,  0.05761837, -0.51950708, -0.00730424,  0.29339437],\n",
              "        [ 0.        ,  0.66412748,  1.29272692,  0.96659501,  1.00321947],\n",
              "        [ 0.        ,  1.42226386,  0.99068792,  1.33180724,  0.29339437],\n",
              "        [ 0.        , -0.09400891, -0.21746808, -0.12904165,  0.29339437],\n",
              "        [ 0.        , -0.24563619,  0.38660992, -0.00730424,  0.29339437],\n",
              "        [ 0.        ,  0.20924564, -0.21746808,  0.84485761,  1.00321947],\n",
              "        [ 0.        ,  1.42226386,  0.38660992,  1.08833242, -0.17982236],\n",
              "        [ 0.        ,  1.72551842, -0.21746808,  1.45354464,  0.53000274],\n",
              "        [ 0.        ,  2.4836548 ,  2.80292193,  1.81875686,  0.7666111 ],\n",
              "        [ 0.        ,  0.20924564, -0.21746808,  0.84485761,  1.23982783],\n",
              "        [ 0.        ,  0.05761837, -0.21746808,  0.23617057, -0.41643072],\n",
              "        [ 0.        , -0.24563619, -0.82154608,  0.84485761, -0.65303909],\n",
              "        [ 0.        ,  2.18040025,  0.38660992,  1.45354464,  1.4764362 ],\n",
              "        [ 0.        ,  0.05761837,  1.59476592,  0.84485761,  1.71304456],\n",
              "        [ 0.        ,  0.20924564,  0.68864892,  0.7231202 ,  0.29339437],\n",
              "        [ 0.        , -0.39726347,  0.38660992, -0.12904165,  0.29339437],\n",
              "        [ 0.        ,  0.96738203,  0.68864892,  0.60138279,  1.00321947],\n",
              "        [ 0.        ,  0.66412748,  0.68864892,  0.84485761,  1.71304456],\n",
              "        [ 0.        ,  0.96738203,  0.68864892,  0.23617057,  1.4764362 ],\n",
              "        [ 0.        , -0.70051802, -0.51950708,  0.23617057,  0.53000274],\n",
              "        [ 0.        ,  0.81575475,  0.99068792,  1.21006983,  1.4764362 ],\n",
              "        [ 0.        ,  0.66412748,  1.29272692,  0.96659501,  1.94965293],\n",
              "        [ 0.        ,  0.66412748,  0.38660992,  0.35790798,  1.4764362 ],\n",
              "        [ 0.        ,  0.05761837, -1.12358508,  0.11443316,  0.53000274],\n",
              "        [ 0.        ,  0.36087292,  0.38660992,  0.35790798,  0.7666111 ],\n",
              "        [ 0.        , -0.09400891,  1.59476592,  0.60138279,  1.4764362 ],\n",
              "        [ 0.        , -0.54889074,  0.38660992,  0.23617057,  0.29339437]]),\n",
              " 0     1\n",
              " 1     1\n",
              " 2     1\n",
              " 3     1\n",
              " 4     1\n",
              "      ..\n",
              " 95    0\n",
              " 96    0\n",
              " 97    0\n",
              " 98    0\n",
              " 99    0\n",
              " Length: 100, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N9AX5_gG8mt"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUjFaNd5G8mt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "aa8e4e34-1ff1-4091-a7f1-4ef4818e7c18"
      },
      "source": [
        "# обучаем на части датасета (train)\n",
        "\n",
        "model.fit(X_train, y_train)\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=500)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=500)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions0 = model.predict(X_test)"
      ],
      "metadata": {
        "id": "WjjmkVKY1Fo9"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "EiRoBMeQvTJA"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnfK25uaG8mu"
      },
      "source": [
        "<p>Получаем наш скор (точность предсказания) на обучающей и тестовой выборках.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfgDEyzHG8mv",
        "outputId": "e9e68be7-9e55-4105-9b61-f33e44cc595b"
      },
      "source": [
        "model.score(X_train, y_train)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9875"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcaZGtL4G8mv",
        "outputId": "66e4cd24-cf99-44bc-91a1-bcb14c14252d"
      },
      "source": [
        "model.score(X_test, y_test)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.85"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Считаем accuracy последней модели"
      ],
      "metadata": {
        "id": "GEB7fwwoneOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score, precision_score, accuracy_score\n"
      ],
      "metadata": {
        "id": "Y0JIiRHWndLd"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "yg6f7jt7nn3_"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE2PIW_TntI5",
        "outputId": "010ff81e-10ea-4dcc-de02-358d1aa91639"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.85"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучим логистическую регрессию при помощи ускоренного по Нестерову метода адаптивной оценки моментов (Nesterov–accelerated Adaptive Moment Estimation, Nadam)"
      ],
      "metadata": {
        "id": "JROjABBN4Mqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nesterov\n",
        "\n",
        "g = 0.95\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def logloss(y, y_proba):\n",
        "    logloss_1 = np.sum(np.log(y_proba[y == 1] + 1e-30))\n",
        "    logloss_0 = np.sum(np.log(1 - y_proba[y == 0] + 1e-30))\n",
        "    logloss_total = -(logloss_0 + logloss_1) / len(y)\n",
        "    return logloss_total\n",
        "\n",
        "\n",
        "def gr_logloss(X, W, y):\n",
        "    y_proba = sigmoid(X @ W)\n",
        "    grad = X.T @ (y_proba - y)\n",
        "    return grad"
      ],
      "metadata": {
        "id": "IU1LLxjP4Lvs"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nesterov\n",
        "# установка минимального значения, на которое должны изменяться веса\n",
        "eps = 0.0001\n",
        "\n",
        "# первоначальня точка\n",
        "#np.random.seed(2)\n",
        "W = np.random.randn(X.shape[1])\n",
        "W = np.where(W == 1, 1, 1)\n",
        "cur_imp = np.where(W == 1, 0, 0)\n",
        "\n",
        "# размер шага (learning rate)\n",
        "learning_rate = 0.01\n",
        "\n",
        "next_W = W\n",
        "\n",
        "# количество итераций\n",
        "n = 100\n",
        "for i in range(n):\n",
        "    cur_W = next_W\n",
        "\n",
        "    # движение в негативную сторону вычисляемого градиента\n",
        "    # next_W = cur_W - learning_rate * gr_logloss(X, cur_W, y)\n",
        "    next_imp = g * cur_imp + learning_rate * gr_logloss(X, cur_W - g * cur_imp, y)\n",
        "    next_W = cur_W - next_imp\n",
        "\n",
        "    # остановка когда достигнута необходимая степень точности\n",
        "    if np.linalg.norm(cur_W - next_W) <= eps:\n",
        "        break\n",
        "\n",
        "    if i % 1 == 0:\n",
        "        print(f\"Итерация: {i}\")\n",
        "        y_proba = sigmoid(X @ next_W)\n",
        "        y_class = np.where(y_proba >= 0.5, 1, 0)\n",
        "        accuracy = (y_class == y).sum() / len(y)\n",
        "        print(f\"Logloss {logloss(y, y_proba)}\")\n",
        "        print(f\"Accuracy {accuracy}\")\n",
        "        print(\"--------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_g70JMZ5JEZ",
        "outputId": "e502fddd-52c5-4677-d513-e4cd49a633a7"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Итерация: 0\n",
            "Logloss 1.2910308882282424\n",
            "Accuracy 0.22\n",
            "--------------------------------------------------------\n",
            "Итерация: 1\n",
            "Logloss 0.47971328600027185\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 2\n",
            "Logloss 0.33937215184892267\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 3\n",
            "Logloss 0.29230496367120734\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 4\n",
            "Logloss 0.26469821673069044\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 5\n",
            "Logloss 0.2452868216750972\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 6\n",
            "Logloss 0.23036939240585455\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 7\n",
            "Logloss 0.21829776410980814\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 8\n",
            "Logloss 0.20819857415842297\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 9\n",
            "Logloss 0.19955260272363154\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 10\n",
            "Logloss 0.19202481974068022\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 11\n",
            "Logloss 0.1853854621575023\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 12\n",
            "Logloss 0.1794694315592929\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 13\n",
            "Logloss 0.17415368228465133\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 14\n",
            "Logloss 0.1693438023107212\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 15\n",
            "Logloss 0.16496562312164506\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 16\n",
            "Logloss 0.16095974040128677\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 17\n",
            "Logloss 0.15727780161023805\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 18\n",
            "Logloss 0.1538799105880311\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 19\n",
            "Logloss 0.15073276359554602\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 20\n",
            "Logloss 0.14780827919357656\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 21\n",
            "Logloss 0.145082570594238\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 22\n",
            "Logloss 0.14253516118397744\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 23\n",
            "Logloss 0.140148376346284\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 24\n",
            "Logloss 0.13790686548689618\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 25\n",
            "Logloss 0.13579722181297682\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 26\n",
            "Logloss 0.13380767659145346\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 27\n",
            "Logloss 0.13192785090639544\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 28\n",
            "Logloss 0.13014855233630654\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 29\n",
            "Logloss 0.12846160710229337\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 30\n",
            "Logloss 0.12685972049923736\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 31\n",
            "Logloss 0.1253363600790288\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 32\n",
            "Logloss 0.12388565728504648\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 33\n",
            "Logloss 0.12250232416134256\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 34\n",
            "Logloss 0.12118158246216172\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 35\n",
            "Logloss 0.11991910302630977\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 36\n",
            "Logloss 0.11871095369835444\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 37\n",
            "Logloss 0.1175535544048703\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 38\n",
            "Logloss 0.11644363825093137\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 39\n",
            "Logloss 0.11537821770602288\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 40\n",
            "Logloss 0.11435455511156153\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 41\n",
            "Logloss 0.11337013687335443\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 42\n",
            "Logloss 0.11242265080846466\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 43\n",
            "Logloss 0.11150996620234854\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 44\n",
            "Logloss 0.1106301162028342\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 45\n",
            "Logloss 0.10978128223566436\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 46\n",
            "Logloss 0.10896178017438783\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 47\n",
            "Logloss 0.10817004803728102\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 48\n",
            "Logloss 0.1074046350172436\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 49\n",
            "Logloss 0.106664191678455\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 50\n",
            "Logloss 0.10594746117697344\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 51\n",
            "Logloss 0.1052532713821904\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 52\n",
            "Logloss 0.1045805277927505\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 53\n",
            "Logloss 0.10392820715472383\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 54\n",
            "Logloss 0.10329535170189516\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 55\n",
            "Logloss 0.10268106394835018\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 56\n",
            "Logloss 0.10208450197238\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 57\n",
            "Logloss 0.10150487513832152\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 58\n",
            "Logloss 0.10094144020949346\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 59\n",
            "Logloss 0.10039349781104169\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 60\n",
            "Logloss 0.09986038920640052\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 61\n",
            "Logloss 0.09934149335532445\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 62\n",
            "Logloss 0.09883622422514043\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 63\n",
            "Logloss 0.09834402833009133\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 64\n",
            "Logloss 0.09786438247645654\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 65\n",
            "Logloss 0.09739679169360016\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 66\n",
            "Logloss 0.096940787333258\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 67\n",
            "Logloss 0.09649592532127539\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 68\n",
            "Logloss 0.09606178454768118\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 69\n",
            "Logloss 0.0956379653824586\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 70\n",
            "Logloss 0.0952240883056787\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 71\n",
            "Logloss 0.09481979264181672\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 72\n",
            "Logloss 0.0944247353890954\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 73\n",
            "Logloss 0.09403859013560935\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 74\n",
            "Logloss 0.09366104605479243\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 75\n",
            "Logloss 0.09329180697351226\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 76\n",
            "Logloss 0.0929305905067173\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 77\n",
            "Logloss 0.09257712725313791\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 78\n",
            "Logloss 0.0922311600470562\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 79\n",
            "Logloss 0.09189244326161969\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 80\n",
            "Logloss 0.09156074215958794\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 81\n",
            "Logloss 0.09123583228777184\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 82\n",
            "Logloss 0.09091749891175921\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 83\n",
            "Logloss 0.09060553648782121\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 84\n",
            "Logloss 0.09029974816916564\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 85\n",
            "Logloss 0.08999994534394665\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 86\n",
            "Logloss 0.08970594720266334\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 87\n",
            "Logloss 0.0894175803327786\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 88\n",
            "Logloss 0.0891346783385715\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 89\n",
            "Logloss 0.08885708148440048\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 90\n",
            "Logloss 0.08858463635970466\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 91\n",
            "Logloss 0.08831719556420531\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 92\n",
            "Logloss 0.08805461741189329\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 93\n",
            "Logloss 0.08779676565250089\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 94\n",
            "Logloss 0.08754350920925834\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 95\n",
            "Logloss 0.08729472193182886\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 96\n",
            "Logloss 0.08705028236340183\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 97\n",
            "Logloss 0.08681007352100079\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 98\n",
            "Logloss 0.08657398268813482\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 99\n",
            "Logloss 0.08634190121898762\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучим логистическую регрессию при помощи метода скользящего среднего (Root Mean Square Propagation, RMSProp)"
      ],
      "metadata": {
        "id": "uHE05dQFJRkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RMSProp\n",
        "# установка минимального значения, на которое должны изменяться веса\n",
        "a=0.1\n",
        "\n",
        "eps = 0.0001\n",
        "\n",
        "# первоначальня точка\n",
        "#np.random.seed(2)\n",
        "W = np.random.randn(X.shape[1])\n",
        "W = np.where(W == 1, 1, 1)\n",
        "cur_g = np.where(W == 1, 0, 0)\n",
        "\n",
        "# размер шага (learning rate)\n",
        "learning_rate = 0.01\n",
        "\n",
        "next_W = W\n",
        "\n",
        "# количество итераций\n",
        "n = 60\n",
        "for i in range(n):\n",
        "    cur_W = next_W\n",
        "\n",
        "    # движение в негативную сторону вычисляемого градиента\n",
        "    # next_W = cur_W - learning_rate * gr_logloss(X, cur_W, y)\n",
        "    next_g = a * cur_g + (1-a) * np.square(gr_logloss(X, cur_W, y))\n",
        "    next_W = cur_W - learning_rate * gr_logloss(X, cur_W, y) / (np.sqrt(g)+eps)\n",
        "\n",
        "    # остановка когда достигнута необходимая степень точности\n",
        "    if np.linalg.norm(cur_W - next_W) <= eps:\n",
        "        break\n",
        "\n",
        "    if i % 1 == 0:\n",
        "        print(f\"Итерация: {i}\")\n",
        "        y_proba = sigmoid(X @ next_W)\n",
        "        y_class = np.where(y_proba >= 0.5, 1, 0)\n",
        "        accuracy = (y_class == y).sum() / len(y)\n",
        "        print(f\"Logloss {logloss(y, y_proba)}\")\n",
        "        print(f\"Accuracy {accuracy}\")\n",
        "        print(\"--------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYhyOS0sJach",
        "outputId": "3be875c8-af2d-474d-be5b-9c2c902f62cd"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Итерация: 0\n",
            "Logloss 1.2571654377555885\n",
            "Accuracy 0.23\n",
            "--------------------------------------------------------\n",
            "Итерация: 1\n",
            "Logloss 0.45981543886056625\n",
            "Accuracy 0.93\n",
            "--------------------------------------------------------\n",
            "Итерация: 2\n",
            "Logloss 0.3327757478879411\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 3\n",
            "Logloss 0.28797760415365664\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 4\n",
            "Logloss 0.2612509675826993\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 5\n",
            "Logloss 0.2422988106219374\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 6\n",
            "Logloss 0.22766424656059267\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 7\n",
            "Logloss 0.2157875587634864\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 8\n",
            "Logloss 0.20583422255937756\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 9\n",
            "Logloss 0.19730429771631683\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 10\n",
            "Logloss 0.18987318327698566\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 11\n",
            "Logloss 0.1833171369855041\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 12\n",
            "Logloss 0.1774747243911115\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 13\n",
            "Logloss 0.17222523274196017\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 14\n",
            "Logloss 0.16747579711445204\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 15\n",
            "Logloss 0.16315331451563872\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 16\n",
            "Logloss 0.15919914119780373\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 17\n",
            "Logloss 0.15556548624402308\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 18\n",
            "Logloss 0.1522128816510595\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 19\n",
            "Logloss 0.14910835986195717\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 20\n",
            "Logloss 0.14622411055059525\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 21\n",
            "Logloss 0.14353647080358636\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 22\n",
            "Logloss 0.14102515270701485\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 23\n",
            "Logloss 0.1386726434980673\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 24\n",
            "Logloss 0.13646373345710855\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 25\n",
            "Logloss 0.1343851399032186\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 26\n",
            "Logloss 0.13242520454435305\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 27\n",
            "Logloss 0.13057364754807008\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 28\n",
            "Logloss 0.12882136598466923\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 29\n",
            "Logloss 0.1271602673499589\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 30\n",
            "Logloss 0.1255831310868917\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 31\n",
            "Logloss 0.12408349264950705\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 32\n",
            "Logloss 0.122655545860684\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 33\n",
            "Logloss 0.12129406022444648\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 34\n",
            "Logloss 0.11999431054536752\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 35\n",
            "Logloss 0.11875201673928411\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 36\n",
            "Logloss 0.11756329213191734\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 37\n",
            "Logloss 0.1164245988646012\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 38\n",
            "Logloss 0.1153327092807098\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 39\n",
            "Logloss 0.11428467236844586\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 40\n",
            "Logloss 0.11327778449727553\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 41\n",
            "Logloss 0.11230956381539581\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 42\n",
            "Logloss 0.11137772778097778\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 43\n",
            "Logloss 0.11048017338572691\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 44\n",
            "Logloss 0.10961495969954552\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 45\n",
            "Logloss 0.10878029242287582\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 46\n",
            "Logloss 0.107974510181077\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 47\n",
            "Logloss 0.10719607233485794\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 48\n",
            "Logloss 0.10644354811386453\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 49\n",
            "Logloss 0.1057156069082101\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 50\n",
            "Logloss 0.10501100957600651\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 51\n",
            "Logloss 0.10432860064457859\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 52\n",
            "Logloss 0.10366730129965142\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 53\n",
            "Logloss 0.1030261030709017\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 54\n",
            "Logloss 0.10240406213427455\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 55\n",
            "Logloss 0.10180029416172719\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 56\n",
            "Logloss 0.10121396965785173\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 57\n",
            "Logloss 0.10064430973038192\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 58\n",
            "Logloss 0.10009058224809296\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 59\n",
            "Logloss 0.09955209834522381\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод\n",
        "\n",
        "Модель градиентного спуска и Метод Нестерова показали одинаковую точность и скорость, Метод скользящего среднего достиг такой же точности за меньшее количество итераций.\n",
        "\n",
        "\n",
        "|Метод градиентного спуска|\n",
        "\n",
        "- Итерация: 56\n",
        "\n",
        "- Logloss 0.10208450197238\n",
        "\n",
        "- Accuracy 0.98\n",
        "\n",
        "\n",
        "|Метод Нестерова|\n",
        "\n",
        "- Итерация: 56\n",
        "\n",
        "- Logloss 0.10208450197238\n",
        "\n",
        "- Accuracy 0.98\n",
        "\n",
        "\n",
        "\n",
        "|Метод скользящего среднего|\n",
        "\n",
        "- Итерация: 54\n",
        "\n",
        "- Logloss 0.10240406213427455\n",
        "\n",
        "- Accuracy 0.98\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CM8wCdmDEa5R"
      }
    }
  ]
}