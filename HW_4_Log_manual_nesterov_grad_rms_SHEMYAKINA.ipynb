{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoFBPfrzU+pLjmFqIk0ahj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VeronikaShe/ML-study_HW_1/blob/main/HW_4_Log_manual_nesterov_grad_rms_SHEMYAKINA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PQ91uuFG8mj"
      },
      "source": [
        "- Загружаем данные.\n",
        "\n",
        "- Используем датасет с ирисами. Оставляем только 2 класса: Iris Versicolor, Iris Virginica.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV3A-0MtG8mW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57136cd5-8776-4cd3-a0cb-410c29e662a1"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd # Для работы с данными\n",
        "import scipy.stats # При работе со статистикой\n",
        "import matplotlib.pyplot as plt  # Библиотека для визуализации результатов\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "!pip install category_encoders\n",
        "from category_encoders.count import CountEncoder"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.8.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.16.0)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "Downloading category_encoders-2.8.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "pho_bO5I4lbV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "iris"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "967w4IEy4uww",
        "outputId": "49b2b24a-c055-4241-c682-5bc6c815d1bd"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
              "        [4.9, 3. , 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.3, 0.2],\n",
              "        [4.6, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.6, 1.4, 0.2],\n",
              "        [5.4, 3.9, 1.7, 0.4],\n",
              "        [4.6, 3.4, 1.4, 0.3],\n",
              "        [5. , 3.4, 1.5, 0.2],\n",
              "        [4.4, 2.9, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.1],\n",
              "        [5.4, 3.7, 1.5, 0.2],\n",
              "        [4.8, 3.4, 1.6, 0.2],\n",
              "        [4.8, 3. , 1.4, 0.1],\n",
              "        [4.3, 3. , 1.1, 0.1],\n",
              "        [5.8, 4. , 1.2, 0.2],\n",
              "        [5.7, 4.4, 1.5, 0.4],\n",
              "        [5.4, 3.9, 1.3, 0.4],\n",
              "        [5.1, 3.5, 1.4, 0.3],\n",
              "        [5.7, 3.8, 1.7, 0.3],\n",
              "        [5.1, 3.8, 1.5, 0.3],\n",
              "        [5.4, 3.4, 1.7, 0.2],\n",
              "        [5.1, 3.7, 1.5, 0.4],\n",
              "        [4.6, 3.6, 1. , 0.2],\n",
              "        [5.1, 3.3, 1.7, 0.5],\n",
              "        [4.8, 3.4, 1.9, 0.2],\n",
              "        [5. , 3. , 1.6, 0.2],\n",
              "        [5. , 3.4, 1.6, 0.4],\n",
              "        [5.2, 3.5, 1.5, 0.2],\n",
              "        [5.2, 3.4, 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.6, 0.2],\n",
              "        [4.8, 3.1, 1.6, 0.2],\n",
              "        [5.4, 3.4, 1.5, 0.4],\n",
              "        [5.2, 4.1, 1.5, 0.1],\n",
              "        [5.5, 4.2, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.2, 1.2, 0.2],\n",
              "        [5.5, 3.5, 1.3, 0.2],\n",
              "        [4.9, 3.6, 1.4, 0.1],\n",
              "        [4.4, 3. , 1.3, 0.2],\n",
              "        [5.1, 3.4, 1.5, 0.2],\n",
              "        [5. , 3.5, 1.3, 0.3],\n",
              "        [4.5, 2.3, 1.3, 0.3],\n",
              "        [4.4, 3.2, 1.3, 0.2],\n",
              "        [5. , 3.5, 1.6, 0.6],\n",
              "        [5.1, 3.8, 1.9, 0.4],\n",
              "        [4.8, 3. , 1.4, 0.3],\n",
              "        [5.1, 3.8, 1.6, 0.2],\n",
              "        [4.6, 3.2, 1.4, 0.2],\n",
              "        [5.3, 3.7, 1.5, 0.2],\n",
              "        [5. , 3.3, 1.4, 0.2],\n",
              "        [7. , 3.2, 4.7, 1.4],\n",
              "        [6.4, 3.2, 4.5, 1.5],\n",
              "        [6.9, 3.1, 4.9, 1.5],\n",
              "        [5.5, 2.3, 4. , 1.3],\n",
              "        [6.5, 2.8, 4.6, 1.5],\n",
              "        [5.7, 2.8, 4.5, 1.3],\n",
              "        [6.3, 3.3, 4.7, 1.6],\n",
              "        [4.9, 2.4, 3.3, 1. ],\n",
              "        [6.6, 2.9, 4.6, 1.3],\n",
              "        [5.2, 2.7, 3.9, 1.4],\n",
              "        [5. , 2. , 3.5, 1. ],\n",
              "        [5.9, 3. , 4.2, 1.5],\n",
              "        [6. , 2.2, 4. , 1. ],\n",
              "        [6.1, 2.9, 4.7, 1.4],\n",
              "        [5.6, 2.9, 3.6, 1.3],\n",
              "        [6.7, 3.1, 4.4, 1.4],\n",
              "        [5.6, 3. , 4.5, 1.5],\n",
              "        [5.8, 2.7, 4.1, 1. ],\n",
              "        [6.2, 2.2, 4.5, 1.5],\n",
              "        [5.6, 2.5, 3.9, 1.1],\n",
              "        [5.9, 3.2, 4.8, 1.8],\n",
              "        [6.1, 2.8, 4. , 1.3],\n",
              "        [6.3, 2.5, 4.9, 1.5],\n",
              "        [6.1, 2.8, 4.7, 1.2],\n",
              "        [6.4, 2.9, 4.3, 1.3],\n",
              "        [6.6, 3. , 4.4, 1.4],\n",
              "        [6.8, 2.8, 4.8, 1.4],\n",
              "        [6.7, 3. , 5. , 1.7],\n",
              "        [6. , 2.9, 4.5, 1.5],\n",
              "        [5.7, 2.6, 3.5, 1. ],\n",
              "        [5.5, 2.4, 3.8, 1.1],\n",
              "        [5.5, 2.4, 3.7, 1. ],\n",
              "        [5.8, 2.7, 3.9, 1.2],\n",
              "        [6. , 2.7, 5.1, 1.6],\n",
              "        [5.4, 3. , 4.5, 1.5],\n",
              "        [6. , 3.4, 4.5, 1.6],\n",
              "        [6.7, 3.1, 4.7, 1.5],\n",
              "        [6.3, 2.3, 4.4, 1.3],\n",
              "        [5.6, 3. , 4.1, 1.3],\n",
              "        [5.5, 2.5, 4. , 1.3],\n",
              "        [5.5, 2.6, 4.4, 1.2],\n",
              "        [6.1, 3. , 4.6, 1.4],\n",
              "        [5.8, 2.6, 4. , 1.2],\n",
              "        [5. , 2.3, 3.3, 1. ],\n",
              "        [5.6, 2.7, 4.2, 1.3],\n",
              "        [5.7, 3. , 4.2, 1.2],\n",
              "        [5.7, 2.9, 4.2, 1.3],\n",
              "        [6.2, 2.9, 4.3, 1.3],\n",
              "        [5.1, 2.5, 3. , 1.1],\n",
              "        [5.7, 2.8, 4.1, 1.3],\n",
              "        [6.3, 3.3, 6. , 2.5],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [7.1, 3. , 5.9, 2.1],\n",
              "        [6.3, 2.9, 5.6, 1.8],\n",
              "        [6.5, 3. , 5.8, 2.2],\n",
              "        [7.6, 3. , 6.6, 2.1],\n",
              "        [4.9, 2.5, 4.5, 1.7],\n",
              "        [7.3, 2.9, 6.3, 1.8],\n",
              "        [6.7, 2.5, 5.8, 1.8],\n",
              "        [7.2, 3.6, 6.1, 2.5],\n",
              "        [6.5, 3.2, 5.1, 2. ],\n",
              "        [6.4, 2.7, 5.3, 1.9],\n",
              "        [6.8, 3. , 5.5, 2.1],\n",
              "        [5.7, 2.5, 5. , 2. ],\n",
              "        [5.8, 2.8, 5.1, 2.4],\n",
              "        [6.4, 3.2, 5.3, 2.3],\n",
              "        [6.5, 3. , 5.5, 1.8],\n",
              "        [7.7, 3.8, 6.7, 2.2],\n",
              "        [7.7, 2.6, 6.9, 2.3],\n",
              "        [6. , 2.2, 5. , 1.5],\n",
              "        [6.9, 3.2, 5.7, 2.3],\n",
              "        [5.6, 2.8, 4.9, 2. ],\n",
              "        [7.7, 2.8, 6.7, 2. ],\n",
              "        [6.3, 2.7, 4.9, 1.8],\n",
              "        [6.7, 3.3, 5.7, 2.1],\n",
              "        [7.2, 3.2, 6. , 1.8],\n",
              "        [6.2, 2.8, 4.8, 1.8],\n",
              "        [6.1, 3. , 4.9, 1.8],\n",
              "        [6.4, 2.8, 5.6, 2.1],\n",
              "        [7.2, 3. , 5.8, 1.6],\n",
              "        [7.4, 2.8, 6.1, 1.9],\n",
              "        [7.9, 3.8, 6.4, 2. ],\n",
              "        [6.4, 2.8, 5.6, 2.2],\n",
              "        [6.3, 2.8, 5.1, 1.5],\n",
              "        [6.1, 2.6, 5.6, 1.4],\n",
              "        [7.7, 3. , 6.1, 2.3],\n",
              "        [6.3, 3.4, 5.6, 2.4],\n",
              "        [6.4, 3.1, 5.5, 1.8],\n",
              "        [6. , 3. , 4.8, 1.8],\n",
              "        [6.9, 3.1, 5.4, 2.1],\n",
              "        [6.7, 3.1, 5.6, 2.4],\n",
              "        [6.9, 3.1, 5.1, 2.3],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [6.8, 3.2, 5.9, 2.3],\n",
              "        [6.7, 3.3, 5.7, 2.5],\n",
              "        [6.7, 3. , 5.2, 2.3],\n",
              "        [6.3, 2.5, 5. , 1.9],\n",
              "        [6.5, 3. , 5.2, 2. ],\n",
              "        [6.2, 3.4, 5.4, 2.3],\n",
              "        [5.9, 3. , 5.1, 1.8]]),\n",
              " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
              " 'frame': None,\n",
              " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
              " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 150 (50 in each of three classes)\\n:Number of Attributes: 4 numeric, predictive attributes and the class\\n:Attribute Information:\\n    - sepal length in cm\\n    - sepal width in cm\\n    - petal length in cm\\n    - petal width in cm\\n    - class:\\n            - Iris-Setosa\\n            - Iris-Versicolour\\n            - Iris-Virginica\\n\\n:Summary Statistics:\\n\\n============== ==== ==== ======= ===== ====================\\n                Min  Max   Mean    SD   Class Correlation\\n============== ==== ==== ======= ===== ====================\\nsepal length:   4.3  7.9   5.84   0.83    0.7826\\nsepal width:    2.0  4.4   3.05   0.43   -0.4194\\npetal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\npetal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n============== ==== ==== ======= ===== ====================\\n\\n:Missing Attribute Values: None\\n:Class Distribution: 33.3% for each of 3 classes.\\n:Creator: R.A. Fisher\\n:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n:Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. dropdown:: References\\n\\n  - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n    Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n    Mathematical Statistics\" (John Wiley, NY, 1950).\\n  - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n    (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n  - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n    Structure and Classification Rule for Recognition in Partially Exposed\\n    Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n    Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n  - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n    on Information Theory, May 1972, 431-433.\\n  - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n    conceptual clustering system finds 3 classes in the data.\\n  - Many, many more ...\\n',\n",
              " 'feature_names': ['sepal length (cm)',\n",
              "  'sepal width (cm)',\n",
              "  'petal length (cm)',\n",
              "  'petal width (cm)'],\n",
              " 'filename': 'iris.csv',\n",
              " 'data_module': 'sklearn.datasets.data'}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJgcTGp9G8mk",
        "outputId": "93513bc7-898c-4843-8cec-1fd2138ff68e"
      },
      "source": [
        "# датасет\n",
        "X = iris.data[50:,:] # забираем данные из датасета\n",
        "y = iris.target[50:]\n",
        "X,y"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[7. , 3.2, 4.7, 1.4],\n",
              "        [6.4, 3.2, 4.5, 1.5],\n",
              "        [6.9, 3.1, 4.9, 1.5],\n",
              "        [5.5, 2.3, 4. , 1.3],\n",
              "        [6.5, 2.8, 4.6, 1.5],\n",
              "        [5.7, 2.8, 4.5, 1.3],\n",
              "        [6.3, 3.3, 4.7, 1.6],\n",
              "        [4.9, 2.4, 3.3, 1. ],\n",
              "        [6.6, 2.9, 4.6, 1.3],\n",
              "        [5.2, 2.7, 3.9, 1.4],\n",
              "        [5. , 2. , 3.5, 1. ],\n",
              "        [5.9, 3. , 4.2, 1.5],\n",
              "        [6. , 2.2, 4. , 1. ],\n",
              "        [6.1, 2.9, 4.7, 1.4],\n",
              "        [5.6, 2.9, 3.6, 1.3],\n",
              "        [6.7, 3.1, 4.4, 1.4],\n",
              "        [5.6, 3. , 4.5, 1.5],\n",
              "        [5.8, 2.7, 4.1, 1. ],\n",
              "        [6.2, 2.2, 4.5, 1.5],\n",
              "        [5.6, 2.5, 3.9, 1.1],\n",
              "        [5.9, 3.2, 4.8, 1.8],\n",
              "        [6.1, 2.8, 4. , 1.3],\n",
              "        [6.3, 2.5, 4.9, 1.5],\n",
              "        [6.1, 2.8, 4.7, 1.2],\n",
              "        [6.4, 2.9, 4.3, 1.3],\n",
              "        [6.6, 3. , 4.4, 1.4],\n",
              "        [6.8, 2.8, 4.8, 1.4],\n",
              "        [6.7, 3. , 5. , 1.7],\n",
              "        [6. , 2.9, 4.5, 1.5],\n",
              "        [5.7, 2.6, 3.5, 1. ],\n",
              "        [5.5, 2.4, 3.8, 1.1],\n",
              "        [5.5, 2.4, 3.7, 1. ],\n",
              "        [5.8, 2.7, 3.9, 1.2],\n",
              "        [6. , 2.7, 5.1, 1.6],\n",
              "        [5.4, 3. , 4.5, 1.5],\n",
              "        [6. , 3.4, 4.5, 1.6],\n",
              "        [6.7, 3.1, 4.7, 1.5],\n",
              "        [6.3, 2.3, 4.4, 1.3],\n",
              "        [5.6, 3. , 4.1, 1.3],\n",
              "        [5.5, 2.5, 4. , 1.3],\n",
              "        [5.5, 2.6, 4.4, 1.2],\n",
              "        [6.1, 3. , 4.6, 1.4],\n",
              "        [5.8, 2.6, 4. , 1.2],\n",
              "        [5. , 2.3, 3.3, 1. ],\n",
              "        [5.6, 2.7, 4.2, 1.3],\n",
              "        [5.7, 3. , 4.2, 1.2],\n",
              "        [5.7, 2.9, 4.2, 1.3],\n",
              "        [6.2, 2.9, 4.3, 1.3],\n",
              "        [5.1, 2.5, 3. , 1.1],\n",
              "        [5.7, 2.8, 4.1, 1.3],\n",
              "        [6.3, 3.3, 6. , 2.5],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [7.1, 3. , 5.9, 2.1],\n",
              "        [6.3, 2.9, 5.6, 1.8],\n",
              "        [6.5, 3. , 5.8, 2.2],\n",
              "        [7.6, 3. , 6.6, 2.1],\n",
              "        [4.9, 2.5, 4.5, 1.7],\n",
              "        [7.3, 2.9, 6.3, 1.8],\n",
              "        [6.7, 2.5, 5.8, 1.8],\n",
              "        [7.2, 3.6, 6.1, 2.5],\n",
              "        [6.5, 3.2, 5.1, 2. ],\n",
              "        [6.4, 2.7, 5.3, 1.9],\n",
              "        [6.8, 3. , 5.5, 2.1],\n",
              "        [5.7, 2.5, 5. , 2. ],\n",
              "        [5.8, 2.8, 5.1, 2.4],\n",
              "        [6.4, 3.2, 5.3, 2.3],\n",
              "        [6.5, 3. , 5.5, 1.8],\n",
              "        [7.7, 3.8, 6.7, 2.2],\n",
              "        [7.7, 2.6, 6.9, 2.3],\n",
              "        [6. , 2.2, 5. , 1.5],\n",
              "        [6.9, 3.2, 5.7, 2.3],\n",
              "        [5.6, 2.8, 4.9, 2. ],\n",
              "        [7.7, 2.8, 6.7, 2. ],\n",
              "        [6.3, 2.7, 4.9, 1.8],\n",
              "        [6.7, 3.3, 5.7, 2.1],\n",
              "        [7.2, 3.2, 6. , 1.8],\n",
              "        [6.2, 2.8, 4.8, 1.8],\n",
              "        [6.1, 3. , 4.9, 1.8],\n",
              "        [6.4, 2.8, 5.6, 2.1],\n",
              "        [7.2, 3. , 5.8, 1.6],\n",
              "        [7.4, 2.8, 6.1, 1.9],\n",
              "        [7.9, 3.8, 6.4, 2. ],\n",
              "        [6.4, 2.8, 5.6, 2.2],\n",
              "        [6.3, 2.8, 5.1, 1.5],\n",
              "        [6.1, 2.6, 5.6, 1.4],\n",
              "        [7.7, 3. , 6.1, 2.3],\n",
              "        [6.3, 3.4, 5.6, 2.4],\n",
              "        [6.4, 3.1, 5.5, 1.8],\n",
              "        [6. , 3. , 4.8, 1.8],\n",
              "        [6.9, 3.1, 5.4, 2.1],\n",
              "        [6.7, 3.1, 5.6, 2.4],\n",
              "        [6.9, 3.1, 5.1, 2.3],\n",
              "        [5.8, 2.7, 5.1, 1.9],\n",
              "        [6.8, 3.2, 5.9, 2.3],\n",
              "        [6.7, 3.3, 5.7, 2.5],\n",
              "        [6.7, 3. , 5.2, 2.3],\n",
              "        [6.3, 2.5, 5. , 1.9],\n",
              "        [6.5, 3. , 5.2, 2. ],\n",
              "        [6.2, 3.4, 5.4, 2.3],\n",
              "        [5.9, 3. , 5.1, 1.8]]),\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.where(y == 1, 1, 0)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_0c7XVsMC7g",
        "outputId": "0d4eb2c4-cc5e-4368-b3db-cb8b26b57d6e"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.c_[np.ones(len(X)), X]\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbjSNAlVYboi",
        "outputId": "1f0dd6ee-7cbd-4e04-f2ef-0c7047eb6047"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1. , 7. , 3.2, 4.7, 1.4],\n",
              "       [1. , 6.4, 3.2, 4.5, 1.5],\n",
              "       [1. , 6.9, 3.1, 4.9, 1.5],\n",
              "       [1. , 5.5, 2.3, 4. , 1.3],\n",
              "       [1. , 6.5, 2.8, 4.6, 1.5],\n",
              "       [1. , 5.7, 2.8, 4.5, 1.3],\n",
              "       [1. , 6.3, 3.3, 4.7, 1.6],\n",
              "       [1. , 4.9, 2.4, 3.3, 1. ],\n",
              "       [1. , 6.6, 2.9, 4.6, 1.3],\n",
              "       [1. , 5.2, 2.7, 3.9, 1.4],\n",
              "       [1. , 5. , 2. , 3.5, 1. ],\n",
              "       [1. , 5.9, 3. , 4.2, 1.5],\n",
              "       [1. , 6. , 2.2, 4. , 1. ],\n",
              "       [1. , 6.1, 2.9, 4.7, 1.4],\n",
              "       [1. , 5.6, 2.9, 3.6, 1.3],\n",
              "       [1. , 6.7, 3.1, 4.4, 1.4],\n",
              "       [1. , 5.6, 3. , 4.5, 1.5],\n",
              "       [1. , 5.8, 2.7, 4.1, 1. ],\n",
              "       [1. , 6.2, 2.2, 4.5, 1.5],\n",
              "       [1. , 5.6, 2.5, 3.9, 1.1],\n",
              "       [1. , 5.9, 3.2, 4.8, 1.8],\n",
              "       [1. , 6.1, 2.8, 4. , 1.3],\n",
              "       [1. , 6.3, 2.5, 4.9, 1.5],\n",
              "       [1. , 6.1, 2.8, 4.7, 1.2],\n",
              "       [1. , 6.4, 2.9, 4.3, 1.3],\n",
              "       [1. , 6.6, 3. , 4.4, 1.4],\n",
              "       [1. , 6.8, 2.8, 4.8, 1.4],\n",
              "       [1. , 6.7, 3. , 5. , 1.7],\n",
              "       [1. , 6. , 2.9, 4.5, 1.5],\n",
              "       [1. , 5.7, 2.6, 3.5, 1. ],\n",
              "       [1. , 5.5, 2.4, 3.8, 1.1],\n",
              "       [1. , 5.5, 2.4, 3.7, 1. ],\n",
              "       [1. , 5.8, 2.7, 3.9, 1.2],\n",
              "       [1. , 6. , 2.7, 5.1, 1.6],\n",
              "       [1. , 5.4, 3. , 4.5, 1.5],\n",
              "       [1. , 6. , 3.4, 4.5, 1.6],\n",
              "       [1. , 6.7, 3.1, 4.7, 1.5],\n",
              "       [1. , 6.3, 2.3, 4.4, 1.3],\n",
              "       [1. , 5.6, 3. , 4.1, 1.3],\n",
              "       [1. , 5.5, 2.5, 4. , 1.3],\n",
              "       [1. , 5.5, 2.6, 4.4, 1.2],\n",
              "       [1. , 6.1, 3. , 4.6, 1.4],\n",
              "       [1. , 5.8, 2.6, 4. , 1.2],\n",
              "       [1. , 5. , 2.3, 3.3, 1. ],\n",
              "       [1. , 5.6, 2.7, 4.2, 1.3],\n",
              "       [1. , 5.7, 3. , 4.2, 1.2],\n",
              "       [1. , 5.7, 2.9, 4.2, 1.3],\n",
              "       [1. , 6.2, 2.9, 4.3, 1.3],\n",
              "       [1. , 5.1, 2.5, 3. , 1.1],\n",
              "       [1. , 5.7, 2.8, 4.1, 1.3],\n",
              "       [1. , 6.3, 3.3, 6. , 2.5],\n",
              "       [1. , 5.8, 2.7, 5.1, 1.9],\n",
              "       [1. , 7.1, 3. , 5.9, 2.1],\n",
              "       [1. , 6.3, 2.9, 5.6, 1.8],\n",
              "       [1. , 6.5, 3. , 5.8, 2.2],\n",
              "       [1. , 7.6, 3. , 6.6, 2.1],\n",
              "       [1. , 4.9, 2.5, 4.5, 1.7],\n",
              "       [1. , 7.3, 2.9, 6.3, 1.8],\n",
              "       [1. , 6.7, 2.5, 5.8, 1.8],\n",
              "       [1. , 7.2, 3.6, 6.1, 2.5],\n",
              "       [1. , 6.5, 3.2, 5.1, 2. ],\n",
              "       [1. , 6.4, 2.7, 5.3, 1.9],\n",
              "       [1. , 6.8, 3. , 5.5, 2.1],\n",
              "       [1. , 5.7, 2.5, 5. , 2. ],\n",
              "       [1. , 5.8, 2.8, 5.1, 2.4],\n",
              "       [1. , 6.4, 3.2, 5.3, 2.3],\n",
              "       [1. , 6.5, 3. , 5.5, 1.8],\n",
              "       [1. , 7.7, 3.8, 6.7, 2.2],\n",
              "       [1. , 7.7, 2.6, 6.9, 2.3],\n",
              "       [1. , 6. , 2.2, 5. , 1.5],\n",
              "       [1. , 6.9, 3.2, 5.7, 2.3],\n",
              "       [1. , 5.6, 2.8, 4.9, 2. ],\n",
              "       [1. , 7.7, 2.8, 6.7, 2. ],\n",
              "       [1. , 6.3, 2.7, 4.9, 1.8],\n",
              "       [1. , 6.7, 3.3, 5.7, 2.1],\n",
              "       [1. , 7.2, 3.2, 6. , 1.8],\n",
              "       [1. , 6.2, 2.8, 4.8, 1.8],\n",
              "       [1. , 6.1, 3. , 4.9, 1.8],\n",
              "       [1. , 6.4, 2.8, 5.6, 2.1],\n",
              "       [1. , 7.2, 3. , 5.8, 1.6],\n",
              "       [1. , 7.4, 2.8, 6.1, 1.9],\n",
              "       [1. , 7.9, 3.8, 6.4, 2. ],\n",
              "       [1. , 6.4, 2.8, 5.6, 2.2],\n",
              "       [1. , 6.3, 2.8, 5.1, 1.5],\n",
              "       [1. , 6.1, 2.6, 5.6, 1.4],\n",
              "       [1. , 7.7, 3. , 6.1, 2.3],\n",
              "       [1. , 6.3, 3.4, 5.6, 2.4],\n",
              "       [1. , 6.4, 3.1, 5.5, 1.8],\n",
              "       [1. , 6. , 3. , 4.8, 1.8],\n",
              "       [1. , 6.9, 3.1, 5.4, 2.1],\n",
              "       [1. , 6.7, 3.1, 5.6, 2.4],\n",
              "       [1. , 6.9, 3.1, 5.1, 2.3],\n",
              "       [1. , 5.8, 2.7, 5.1, 1.9],\n",
              "       [1. , 6.8, 3.2, 5.9, 2.3],\n",
              "       [1. , 6.7, 3.3, 5.7, 2.5],\n",
              "       [1. , 6.7, 3. , 5.2, 2.3],\n",
              "       [1. , 6.3, 2.5, 5. , 1.9],\n",
              "       [1. , 6.5, 3. , 5.2, 2. ],\n",
              "       [1. , 6.2, 3.4, 5.4, 2.3],\n",
              "       [1. , 5.9, 3. , 5.1, 1.8]])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X[:, 1], X[:, 2], c=y);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "RUWJmPEgwoED",
        "outputId": "e2a8c6bd-def2-4e78-ab2d-40a03f23b526"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.c_[np.ones(len(X)), X]"
      ],
      "metadata": {
        "id": "-J6Kp0E2lLiM"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Масштабируем наши признаки"
      ],
      "metadata": {
        "id": "EX0K5MgCVD8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  scaler = StandardScaler()\n",
        "  X = scaler.fit_transform(X)\n",
        "  X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iv_VIjQ3xqbC",
        "outputId": "92a2288f-adac-49bb-9c32-8768010ff0b0"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  1.11900931,  0.99068792, -0.25077906,\n",
              "        -0.65303909],\n",
              "       [ 0.        ,  0.        ,  0.20924564,  0.99068792, -0.49425387,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        ,  0.96738203,  0.68864892, -0.00730424,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        , -1.15539985, -1.72766308, -1.10294091,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        ,  0.36087292, -0.21746808, -0.37251647,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        , -0.8521453 , -0.21746808, -0.49425387,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        ,  0.05761837,  1.29272692, -0.25077906,\n",
              "        -0.17982236],\n",
              "       [ 0.        ,  0.        , -2.06516352, -1.42562408, -1.95510276,\n",
              "        -1.59947255],\n",
              "       [ 0.        ,  0.        ,  0.5125002 ,  0.08457092, -0.37251647,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        , -1.61028169, -0.51950708, -1.22467832,\n",
              "        -0.65303909],\n",
              "       [ 0.        ,  0.        , -1.91353624, -2.63378009, -1.71162795,\n",
              "        -1.59947255],\n",
              "       [ 0.        ,  0.        , -0.54889074,  0.38660992, -0.8594661 ,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        , -0.39726347, -2.02970209, -1.10294091,\n",
              "        -1.59947255],\n",
              "       [ 0.        ,  0.        , -0.24563619,  0.08457092, -0.25077906,\n",
              "        -0.65303909],\n",
              "       [ 0.        ,  0.        , -1.00377258,  0.08457092, -1.58989054,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        ,  0.66412748,  0.68864892, -0.61599128,\n",
              "        -0.65303909],\n",
              "       [ 0.        ,  0.        , -1.00377258,  0.38660992, -0.49425387,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        , -0.70051802, -0.51950708, -0.9812035 ,\n",
              "        -1.59947255],\n",
              "       [ 0.        ,  0.        , -0.09400891, -2.02970209, -0.49425387,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        , -1.00377258, -1.12358508, -1.22467832,\n",
              "        -1.36286418],\n",
              "       [ 0.        ,  0.        , -0.54889074,  0.99068792, -0.12904165,\n",
              "         0.29339437],\n",
              "       [ 0.        ,  0.        , -0.24563619, -0.21746808, -1.10294091,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        ,  0.05761837, -1.12358508, -0.00730424,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        , -0.24563619, -0.21746808, -0.25077906,\n",
              "        -1.12625582],\n",
              "       [ 0.        ,  0.        ,  0.20924564,  0.08457092, -0.73772869,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        ,  0.5125002 ,  0.38660992, -0.61599128,\n",
              "        -0.65303909],\n",
              "       [ 0.        ,  0.        ,  0.81575475, -0.21746808, -0.12904165,\n",
              "        -0.65303909],\n",
              "       [ 0.        ,  0.        ,  0.66412748,  0.38660992,  0.11443316,\n",
              "         0.05678601],\n",
              "       [ 0.        ,  0.        , -0.39726347,  0.08457092, -0.49425387,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        , -0.8521453 , -0.82154608, -1.71162795,\n",
              "        -1.59947255],\n",
              "       [ 0.        ,  0.        , -1.15539985, -1.42562408, -1.34641572,\n",
              "        -1.36286418],\n",
              "       [ 0.        ,  0.        , -1.15539985, -1.42562408, -1.46815313,\n",
              "        -1.59947255],\n",
              "       [ 0.        ,  0.        , -0.70051802, -0.51950708, -1.22467832,\n",
              "        -1.12625582],\n",
              "       [ 0.        ,  0.        , -0.39726347, -0.51950708,  0.23617057,\n",
              "        -0.17982236],\n",
              "       [ 0.        ,  0.        , -1.30702713,  0.38660992, -0.49425387,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        , -0.39726347,  1.59476592, -0.49425387,\n",
              "        -0.17982236],\n",
              "       [ 0.        ,  0.        ,  0.66412748,  0.68864892, -0.25077906,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        ,  0.05761837, -1.72766308, -0.61599128,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        , -1.00377258,  0.38660992, -0.9812035 ,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        , -1.15539985, -1.12358508, -1.10294091,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        , -1.15539985, -0.82154608, -0.61599128,\n",
              "        -1.12625582],\n",
              "       [ 0.        ,  0.        , -0.24563619,  0.38660992, -0.37251647,\n",
              "        -0.65303909],\n",
              "       [ 0.        ,  0.        , -0.70051802, -0.82154608, -1.10294091,\n",
              "        -1.12625582],\n",
              "       [ 0.        ,  0.        , -1.91353624, -1.72766308, -1.95510276,\n",
              "        -1.59947255],\n",
              "       [ 0.        ,  0.        , -1.00377258, -0.51950708, -0.8594661 ,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        , -0.8521453 ,  0.38660992, -0.8594661 ,\n",
              "        -1.12625582],\n",
              "       [ 0.        ,  0.        , -0.8521453 ,  0.08457092, -0.8594661 ,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        , -0.09400891,  0.08457092, -0.73772869,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        , -1.76190896, -1.12358508, -2.32031498,\n",
              "        -1.36286418],\n",
              "       [ 0.        ,  0.        , -0.8521453 , -0.21746808, -0.9812035 ,\n",
              "        -0.88964745],\n",
              "       [ 0.        ,  0.        ,  0.05761837,  1.29272692,  1.33180724,\n",
              "         1.94965293],\n",
              "       [ 0.        ,  0.        , -0.70051802, -0.51950708,  0.23617057,\n",
              "         0.53000274],\n",
              "       [ 0.        ,  0.        ,  1.27063658,  0.38660992,  1.21006983,\n",
              "         1.00321947],\n",
              "       [ 0.        ,  0.        ,  0.05761837,  0.08457092,  0.84485761,\n",
              "         0.29339437],\n",
              "       [ 0.        ,  0.        ,  0.36087292,  0.38660992,  1.08833242,\n",
              "         1.23982783],\n",
              "       [ 0.        ,  0.        ,  2.02877297,  0.38660992,  2.06223168,\n",
              "         1.00321947],\n",
              "       [ 0.        ,  0.        , -2.06516352, -1.12358508, -0.49425387,\n",
              "         0.05678601],\n",
              "       [ 0.        ,  0.        ,  1.57389114,  0.08457092,  1.69701946,\n",
              "         0.29339437],\n",
              "       [ 0.        ,  0.        ,  0.66412748, -1.12358508,  1.08833242,\n",
              "         0.29339437],\n",
              "       [ 0.        ,  0.        ,  1.42226386,  2.19884393,  1.45354464,\n",
              "         1.94965293],\n",
              "       [ 0.        ,  0.        ,  0.36087292,  0.99068792,  0.23617057,\n",
              "         0.7666111 ],\n",
              "       [ 0.        ,  0.        ,  0.20924564, -0.51950708,  0.47964538,\n",
              "         0.53000274],\n",
              "       [ 0.        ,  0.        ,  0.81575475,  0.38660992,  0.7231202 ,\n",
              "         1.00321947],\n",
              "       [ 0.        ,  0.        , -0.8521453 , -1.12358508,  0.11443316,\n",
              "         0.7666111 ],\n",
              "       [ 0.        ,  0.        , -0.70051802, -0.21746808,  0.23617057,\n",
              "         1.71304456],\n",
              "       [ 0.        ,  0.        ,  0.20924564,  0.99068792,  0.47964538,\n",
              "         1.4764362 ],\n",
              "       [ 0.        ,  0.        ,  0.36087292,  0.38660992,  0.7231202 ,\n",
              "         0.29339437],\n",
              "       [ 0.        ,  0.        ,  2.18040025,  2.80292193,  2.18396909,\n",
              "         1.23982783],\n",
              "       [ 0.        ,  0.        ,  2.18040025, -0.82154608,  2.4274439 ,\n",
              "         1.4764362 ],\n",
              "       [ 0.        ,  0.        , -0.39726347, -2.02970209,  0.11443316,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        ,  0.96738203,  0.99068792,  0.96659501,\n",
              "         1.4764362 ],\n",
              "       [ 0.        ,  0.        , -1.00377258, -0.21746808, -0.00730424,\n",
              "         0.7666111 ],\n",
              "       [ 0.        ,  0.        ,  2.18040025, -0.21746808,  2.18396909,\n",
              "         0.7666111 ],\n",
              "       [ 0.        ,  0.        ,  0.05761837, -0.51950708, -0.00730424,\n",
              "         0.29339437],\n",
              "       [ 0.        ,  0.        ,  0.66412748,  1.29272692,  0.96659501,\n",
              "         1.00321947],\n",
              "       [ 0.        ,  0.        ,  1.42226386,  0.99068792,  1.33180724,\n",
              "         0.29339437],\n",
              "       [ 0.        ,  0.        , -0.09400891, -0.21746808, -0.12904165,\n",
              "         0.29339437],\n",
              "       [ 0.        ,  0.        , -0.24563619,  0.38660992, -0.00730424,\n",
              "         0.29339437],\n",
              "       [ 0.        ,  0.        ,  0.20924564, -0.21746808,  0.84485761,\n",
              "         1.00321947],\n",
              "       [ 0.        ,  0.        ,  1.42226386,  0.38660992,  1.08833242,\n",
              "        -0.17982236],\n",
              "       [ 0.        ,  0.        ,  1.72551842, -0.21746808,  1.45354464,\n",
              "         0.53000274],\n",
              "       [ 0.        ,  0.        ,  2.4836548 ,  2.80292193,  1.81875686,\n",
              "         0.7666111 ],\n",
              "       [ 0.        ,  0.        ,  0.20924564, -0.21746808,  0.84485761,\n",
              "         1.23982783],\n",
              "       [ 0.        ,  0.        ,  0.05761837, -0.21746808,  0.23617057,\n",
              "        -0.41643072],\n",
              "       [ 0.        ,  0.        , -0.24563619, -0.82154608,  0.84485761,\n",
              "        -0.65303909],\n",
              "       [ 0.        ,  0.        ,  2.18040025,  0.38660992,  1.45354464,\n",
              "         1.4764362 ],\n",
              "       [ 0.        ,  0.        ,  0.05761837,  1.59476592,  0.84485761,\n",
              "         1.71304456],\n",
              "       [ 0.        ,  0.        ,  0.20924564,  0.68864892,  0.7231202 ,\n",
              "         0.29339437],\n",
              "       [ 0.        ,  0.        , -0.39726347,  0.38660992, -0.12904165,\n",
              "         0.29339437],\n",
              "       [ 0.        ,  0.        ,  0.96738203,  0.68864892,  0.60138279,\n",
              "         1.00321947],\n",
              "       [ 0.        ,  0.        ,  0.66412748,  0.68864892,  0.84485761,\n",
              "         1.71304456],\n",
              "       [ 0.        ,  0.        ,  0.96738203,  0.68864892,  0.23617057,\n",
              "         1.4764362 ],\n",
              "       [ 0.        ,  0.        , -0.70051802, -0.51950708,  0.23617057,\n",
              "         0.53000274],\n",
              "       [ 0.        ,  0.        ,  0.81575475,  0.99068792,  1.21006983,\n",
              "         1.4764362 ],\n",
              "       [ 0.        ,  0.        ,  0.66412748,  1.29272692,  0.96659501,\n",
              "         1.94965293],\n",
              "       [ 0.        ,  0.        ,  0.66412748,  0.38660992,  0.35790798,\n",
              "         1.4764362 ],\n",
              "       [ 0.        ,  0.        ,  0.05761837, -1.12358508,  0.11443316,\n",
              "         0.53000274],\n",
              "       [ 0.        ,  0.        ,  0.36087292,  0.38660992,  0.35790798,\n",
              "         0.7666111 ],\n",
              "       [ 0.        ,  0.        , -0.09400891,  1.59476592,  0.60138279,\n",
              "         1.4764362 ],\n",
              "       [ 0.        ,  0.        , -0.54889074,  0.38660992,  0.23617057,\n",
              "         0.29339437]])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализуем функцию:\n",
        "\n",
        "logloss - функция логистической функции потерь (cross entropy)  logloss=−1n∑(yi⋅log(pi)+(1−yi)⋅log(1−pi))\n",
        "gr_logloss - градиент функции logloss записанные в матричном виде.  XT(σ(XW)−Y)"
      ],
      "metadata": {
        "id": "1pRk9oVw82YV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzbVvH7DG8ml"
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def logloss(y, y_proba):\n",
        "    logloss_1 = np.sum(np.log(y_proba[y == 1] + 1e-30))\n",
        "    logloss_0 = np.sum(np.log(1 - y_proba[y == 0] + 1e-30))\n",
        "    logloss_total = -(logloss_0 + logloss_1) / len(y)\n",
        "    return logloss_total\n",
        "\n",
        "\n",
        "def gr_logloss(X, W, y):\n",
        "    y_proba = sigmoid(X @ W)\n",
        "    grad = X.T @ (y_proba - y)\n",
        "    return grad"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучим логистическую регрессию при помощи градиентного спуска."
      ],
      "metadata": {
        "id": "Z-9VfsPkVi3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# установка минимального значения, на которое должны изменяться веса\n",
        "eps = 0.0001\n",
        "\n",
        "# первоначальное точка\n",
        "#np.random.seed(2)\n",
        "W = np.random.randn(X.shape[1])\n",
        "W = np.where(W == 1, 1, 1)\n",
        "\n",
        "# размер шага (learning rate)\n",
        "learning_rate = 0.01\n",
        "\n",
        "next_W = W\n",
        "\n",
        "# количество итераций\n",
        "n = 70\n",
        "for i in range(n):\n",
        "    cur_W = next_W\n",
        "\n",
        "    # движение в негативную сторону вычисляемого градиента\n",
        "    next_W = cur_W - learning_rate * gr_logloss(X, cur_W, y)\n",
        "\n",
        "    # остановка когда достигнута необходимая степень точности\n",
        "    if np.linalg.norm(cur_W - next_W) <= eps:\n",
        "        break\n",
        "\n",
        "    if i % 1 == 0:\n",
        "        print(f\"Итерация: {i}\")\n",
        "        y_proba = sigmoid(X @ next_W)\n",
        "        y_class = np.where(y_proba >= 0.5, 1, 0)\n",
        "        accuracy = (y_class == y).sum() / len(y)\n",
        "        print(f\"Logloss {logloss(y, y_proba)}\")\n",
        "        print(f\"Accuracy {accuracy}\")\n",
        "        print(\"--------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rHINxwdYy1E",
        "outputId": "2bed461d-d2be-4923-c317-c178d70e8470"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Итерация: 0\n",
            "Logloss 1.2910308882282424\n",
            "Accuracy 0.22\n",
            "--------------------------------------------------------\n",
            "Итерация: 1\n",
            "Logloss 0.47971328600027185\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 2\n",
            "Logloss 0.33937215184892267\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 3\n",
            "Logloss 0.29230496367120734\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 4\n",
            "Logloss 0.26469821673069044\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 5\n",
            "Logloss 0.2452868216750972\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 6\n",
            "Logloss 0.23036939240585455\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 7\n",
            "Logloss 0.21829776410980814\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 8\n",
            "Logloss 0.20819857415842297\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 9\n",
            "Logloss 0.19955260272363154\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 10\n",
            "Logloss 0.19202481974068022\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 11\n",
            "Logloss 0.1853854621575023\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 12\n",
            "Logloss 0.1794694315592929\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 13\n",
            "Logloss 0.17415368228465133\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 14\n",
            "Logloss 0.1693438023107212\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 15\n",
            "Logloss 0.16496562312164506\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 16\n",
            "Logloss 0.16095974040128677\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 17\n",
            "Logloss 0.15727780161023805\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 18\n",
            "Logloss 0.1538799105880311\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 19\n",
            "Logloss 0.15073276359554602\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 20\n",
            "Logloss 0.14780827919357656\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 21\n",
            "Logloss 0.145082570594238\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 22\n",
            "Logloss 0.14253516118397744\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 23\n",
            "Logloss 0.140148376346284\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 24\n",
            "Logloss 0.13790686548689618\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 25\n",
            "Logloss 0.13579722181297682\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 26\n",
            "Logloss 0.13380767659145346\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 27\n",
            "Logloss 0.13192785090639544\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 28\n",
            "Logloss 0.13014855233630654\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 29\n",
            "Logloss 0.12846160710229337\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 30\n",
            "Logloss 0.12685972049923736\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 31\n",
            "Logloss 0.1253363600790288\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 32\n",
            "Logloss 0.12388565728504648\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 33\n",
            "Logloss 0.12250232416134256\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 34\n",
            "Logloss 0.12118158246216172\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 35\n",
            "Logloss 0.11991910302630977\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 36\n",
            "Logloss 0.11871095369835444\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 37\n",
            "Logloss 0.1175535544048703\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 38\n",
            "Logloss 0.11644363825093137\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 39\n",
            "Logloss 0.11537821770602288\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 40\n",
            "Logloss 0.11435455511156153\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 41\n",
            "Logloss 0.11337013687335443\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 42\n",
            "Logloss 0.11242265080846466\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 43\n",
            "Logloss 0.11150996620234854\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 44\n",
            "Logloss 0.1106301162028342\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 45\n",
            "Logloss 0.10978128223566436\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 46\n",
            "Logloss 0.10896178017438783\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 47\n",
            "Logloss 0.10817004803728102\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 48\n",
            "Logloss 0.1074046350172436\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 49\n",
            "Logloss 0.106664191678455\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 50\n",
            "Logloss 0.10594746117697344\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 51\n",
            "Logloss 0.1052532713821904\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 52\n",
            "Logloss 0.1045805277927505\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 53\n",
            "Logloss 0.10392820715472383\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 54\n",
            "Logloss 0.10329535170189516\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 55\n",
            "Logloss 0.10268106394835018\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 56\n",
            "Logloss 0.10208450197238\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 57\n",
            "Logloss 0.10150487513832152\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 58\n",
            "Logloss 0.10094144020949346\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 59\n",
            "Logloss 0.10039349781104169\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 60\n",
            "Logloss 0.09986038920640052\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 61\n",
            "Logloss 0.09934149335532445\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 62\n",
            "Logloss 0.09883622422514043\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 63\n",
            "Logloss 0.09834402833009133\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 64\n",
            "Logloss 0.09786438247645654\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 65\n",
            "Logloss 0.09739679169360016\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 66\n",
            "Logloss 0.096940787333258\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 67\n",
            "Logloss 0.09649592532127539\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 68\n",
            "Logloss 0.09606178454768118\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 69\n",
            "Logloss 0.0956379653824586\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сравним с модеделью из коробки"
      ],
      "metadata": {
        "id": "OdI_we-yUKrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "model = LogisticRegression(max_iter=500)"
      ],
      "metadata": {
        "id": "p-_DbxeTZjxe"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.Series(data = np.ravel(y))\n",
        "X,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8dyPSiDZ-MG",
        "outputId": "43514b9a-b76e-449f-93de-090574cd93b5"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 0.        ,  1.11900931,  0.99068792, -0.25077906, -0.65303909],\n",
              "        [ 0.        ,  0.20924564,  0.99068792, -0.49425387, -0.41643072],\n",
              "        [ 0.        ,  0.96738203,  0.68864892, -0.00730424, -0.41643072],\n",
              "        [ 0.        , -1.15539985, -1.72766308, -1.10294091, -0.88964745],\n",
              "        [ 0.        ,  0.36087292, -0.21746808, -0.37251647, -0.41643072],\n",
              "        [ 0.        , -0.8521453 , -0.21746808, -0.49425387, -0.88964745],\n",
              "        [ 0.        ,  0.05761837,  1.29272692, -0.25077906, -0.17982236],\n",
              "        [ 0.        , -2.06516352, -1.42562408, -1.95510276, -1.59947255],\n",
              "        [ 0.        ,  0.5125002 ,  0.08457092, -0.37251647, -0.88964745],\n",
              "        [ 0.        , -1.61028169, -0.51950708, -1.22467832, -0.65303909],\n",
              "        [ 0.        , -1.91353624, -2.63378009, -1.71162795, -1.59947255],\n",
              "        [ 0.        , -0.54889074,  0.38660992, -0.8594661 , -0.41643072],\n",
              "        [ 0.        , -0.39726347, -2.02970209, -1.10294091, -1.59947255],\n",
              "        [ 0.        , -0.24563619,  0.08457092, -0.25077906, -0.65303909],\n",
              "        [ 0.        , -1.00377258,  0.08457092, -1.58989054, -0.88964745],\n",
              "        [ 0.        ,  0.66412748,  0.68864892, -0.61599128, -0.65303909],\n",
              "        [ 0.        , -1.00377258,  0.38660992, -0.49425387, -0.41643072],\n",
              "        [ 0.        , -0.70051802, -0.51950708, -0.9812035 , -1.59947255],\n",
              "        [ 0.        , -0.09400891, -2.02970209, -0.49425387, -0.41643072],\n",
              "        [ 0.        , -1.00377258, -1.12358508, -1.22467832, -1.36286418],\n",
              "        [ 0.        , -0.54889074,  0.99068792, -0.12904165,  0.29339437],\n",
              "        [ 0.        , -0.24563619, -0.21746808, -1.10294091, -0.88964745],\n",
              "        [ 0.        ,  0.05761837, -1.12358508, -0.00730424, -0.41643072],\n",
              "        [ 0.        , -0.24563619, -0.21746808, -0.25077906, -1.12625582],\n",
              "        [ 0.        ,  0.20924564,  0.08457092, -0.73772869, -0.88964745],\n",
              "        [ 0.        ,  0.5125002 ,  0.38660992, -0.61599128, -0.65303909],\n",
              "        [ 0.        ,  0.81575475, -0.21746808, -0.12904165, -0.65303909],\n",
              "        [ 0.        ,  0.66412748,  0.38660992,  0.11443316,  0.05678601],\n",
              "        [ 0.        , -0.39726347,  0.08457092, -0.49425387, -0.41643072],\n",
              "        [ 0.        , -0.8521453 , -0.82154608, -1.71162795, -1.59947255],\n",
              "        [ 0.        , -1.15539985, -1.42562408, -1.34641572, -1.36286418],\n",
              "        [ 0.        , -1.15539985, -1.42562408, -1.46815313, -1.59947255],\n",
              "        [ 0.        , -0.70051802, -0.51950708, -1.22467832, -1.12625582],\n",
              "        [ 0.        , -0.39726347, -0.51950708,  0.23617057, -0.17982236],\n",
              "        [ 0.        , -1.30702713,  0.38660992, -0.49425387, -0.41643072],\n",
              "        [ 0.        , -0.39726347,  1.59476592, -0.49425387, -0.17982236],\n",
              "        [ 0.        ,  0.66412748,  0.68864892, -0.25077906, -0.41643072],\n",
              "        [ 0.        ,  0.05761837, -1.72766308, -0.61599128, -0.88964745],\n",
              "        [ 0.        , -1.00377258,  0.38660992, -0.9812035 , -0.88964745],\n",
              "        [ 0.        , -1.15539985, -1.12358508, -1.10294091, -0.88964745],\n",
              "        [ 0.        , -1.15539985, -0.82154608, -0.61599128, -1.12625582],\n",
              "        [ 0.        , -0.24563619,  0.38660992, -0.37251647, -0.65303909],\n",
              "        [ 0.        , -0.70051802, -0.82154608, -1.10294091, -1.12625582],\n",
              "        [ 0.        , -1.91353624, -1.72766308, -1.95510276, -1.59947255],\n",
              "        [ 0.        , -1.00377258, -0.51950708, -0.8594661 , -0.88964745],\n",
              "        [ 0.        , -0.8521453 ,  0.38660992, -0.8594661 , -1.12625582],\n",
              "        [ 0.        , -0.8521453 ,  0.08457092, -0.8594661 , -0.88964745],\n",
              "        [ 0.        , -0.09400891,  0.08457092, -0.73772869, -0.88964745],\n",
              "        [ 0.        , -1.76190896, -1.12358508, -2.32031498, -1.36286418],\n",
              "        [ 0.        , -0.8521453 , -0.21746808, -0.9812035 , -0.88964745],\n",
              "        [ 0.        ,  0.05761837,  1.29272692,  1.33180724,  1.94965293],\n",
              "        [ 0.        , -0.70051802, -0.51950708,  0.23617057,  0.53000274],\n",
              "        [ 0.        ,  1.27063658,  0.38660992,  1.21006983,  1.00321947],\n",
              "        [ 0.        ,  0.05761837,  0.08457092,  0.84485761,  0.29339437],\n",
              "        [ 0.        ,  0.36087292,  0.38660992,  1.08833242,  1.23982783],\n",
              "        [ 0.        ,  2.02877297,  0.38660992,  2.06223168,  1.00321947],\n",
              "        [ 0.        , -2.06516352, -1.12358508, -0.49425387,  0.05678601],\n",
              "        [ 0.        ,  1.57389114,  0.08457092,  1.69701946,  0.29339437],\n",
              "        [ 0.        ,  0.66412748, -1.12358508,  1.08833242,  0.29339437],\n",
              "        [ 0.        ,  1.42226386,  2.19884393,  1.45354464,  1.94965293],\n",
              "        [ 0.        ,  0.36087292,  0.99068792,  0.23617057,  0.7666111 ],\n",
              "        [ 0.        ,  0.20924564, -0.51950708,  0.47964538,  0.53000274],\n",
              "        [ 0.        ,  0.81575475,  0.38660992,  0.7231202 ,  1.00321947],\n",
              "        [ 0.        , -0.8521453 , -1.12358508,  0.11443316,  0.7666111 ],\n",
              "        [ 0.        , -0.70051802, -0.21746808,  0.23617057,  1.71304456],\n",
              "        [ 0.        ,  0.20924564,  0.99068792,  0.47964538,  1.4764362 ],\n",
              "        [ 0.        ,  0.36087292,  0.38660992,  0.7231202 ,  0.29339437],\n",
              "        [ 0.        ,  2.18040025,  2.80292193,  2.18396909,  1.23982783],\n",
              "        [ 0.        ,  2.18040025, -0.82154608,  2.4274439 ,  1.4764362 ],\n",
              "        [ 0.        , -0.39726347, -2.02970209,  0.11443316, -0.41643072],\n",
              "        [ 0.        ,  0.96738203,  0.99068792,  0.96659501,  1.4764362 ],\n",
              "        [ 0.        , -1.00377258, -0.21746808, -0.00730424,  0.7666111 ],\n",
              "        [ 0.        ,  2.18040025, -0.21746808,  2.18396909,  0.7666111 ],\n",
              "        [ 0.        ,  0.05761837, -0.51950708, -0.00730424,  0.29339437],\n",
              "        [ 0.        ,  0.66412748,  1.29272692,  0.96659501,  1.00321947],\n",
              "        [ 0.        ,  1.42226386,  0.99068792,  1.33180724,  0.29339437],\n",
              "        [ 0.        , -0.09400891, -0.21746808, -0.12904165,  0.29339437],\n",
              "        [ 0.        , -0.24563619,  0.38660992, -0.00730424,  0.29339437],\n",
              "        [ 0.        ,  0.20924564, -0.21746808,  0.84485761,  1.00321947],\n",
              "        [ 0.        ,  1.42226386,  0.38660992,  1.08833242, -0.17982236],\n",
              "        [ 0.        ,  1.72551842, -0.21746808,  1.45354464,  0.53000274],\n",
              "        [ 0.        ,  2.4836548 ,  2.80292193,  1.81875686,  0.7666111 ],\n",
              "        [ 0.        ,  0.20924564, -0.21746808,  0.84485761,  1.23982783],\n",
              "        [ 0.        ,  0.05761837, -0.21746808,  0.23617057, -0.41643072],\n",
              "        [ 0.        , -0.24563619, -0.82154608,  0.84485761, -0.65303909],\n",
              "        [ 0.        ,  2.18040025,  0.38660992,  1.45354464,  1.4764362 ],\n",
              "        [ 0.        ,  0.05761837,  1.59476592,  0.84485761,  1.71304456],\n",
              "        [ 0.        ,  0.20924564,  0.68864892,  0.7231202 ,  0.29339437],\n",
              "        [ 0.        , -0.39726347,  0.38660992, -0.12904165,  0.29339437],\n",
              "        [ 0.        ,  0.96738203,  0.68864892,  0.60138279,  1.00321947],\n",
              "        [ 0.        ,  0.66412748,  0.68864892,  0.84485761,  1.71304456],\n",
              "        [ 0.        ,  0.96738203,  0.68864892,  0.23617057,  1.4764362 ],\n",
              "        [ 0.        , -0.70051802, -0.51950708,  0.23617057,  0.53000274],\n",
              "        [ 0.        ,  0.81575475,  0.99068792,  1.21006983,  1.4764362 ],\n",
              "        [ 0.        ,  0.66412748,  1.29272692,  0.96659501,  1.94965293],\n",
              "        [ 0.        ,  0.66412748,  0.38660992,  0.35790798,  1.4764362 ],\n",
              "        [ 0.        ,  0.05761837, -1.12358508,  0.11443316,  0.53000274],\n",
              "        [ 0.        ,  0.36087292,  0.38660992,  0.35790798,  0.7666111 ],\n",
              "        [ 0.        , -0.09400891,  1.59476592,  0.60138279,  1.4764362 ],\n",
              "        [ 0.        , -0.54889074,  0.38660992,  0.23617057,  0.29339437]]),\n",
              " 0     1\n",
              " 1     1\n",
              " 2     1\n",
              " 3     1\n",
              " 4     1\n",
              "      ..\n",
              " 95    0\n",
              " 96    0\n",
              " 97    0\n",
              " 98    0\n",
              " 99    0\n",
              " Length: 100, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N9AX5_gG8mt"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUjFaNd5G8mt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "aa8e4e34-1ff1-4091-a7f1-4ef4818e7c18"
      },
      "source": [
        "# обучаем на части датасета (train)\n",
        "\n",
        "model.fit(X_train, y_train)\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=500)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=500)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions0 = model.predict(X_test)"
      ],
      "metadata": {
        "id": "WjjmkVKY1Fo9"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "EiRoBMeQvTJA"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnfK25uaG8mu"
      },
      "source": [
        "<p>Получаем наш скор (точность предсказания) на обучающей и тестовой выборках.</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfgDEyzHG8mv",
        "outputId": "e9e68be7-9e55-4105-9b61-f33e44cc595b"
      },
      "source": [
        "model.score(X_train, y_train)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9875"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcaZGtL4G8mv",
        "outputId": "66e4cd24-cf99-44bc-91a1-bcb14c14252d"
      },
      "source": [
        "model.score(X_test, y_test)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.85"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Считаем accuracy последней модели"
      ],
      "metadata": {
        "id": "GEB7fwwoneOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score, precision_score, accuracy_score\n"
      ],
      "metadata": {
        "id": "Y0JIiRHWndLd"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "yg6f7jt7nn3_"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE2PIW_TntI5",
        "outputId": "010ff81e-10ea-4dcc-de02-358d1aa91639"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.85"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучим логистическую регрессию при помощи ускоренного по Нестерову метода адаптивной оценки моментов (Nesterov–accelerated Adaptive Moment Estimation, Nadam)"
      ],
      "metadata": {
        "id": "JROjABBN4Mqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nesterov\n",
        "\n",
        "g = 0.95\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def logloss(y, y_proba):\n",
        "    logloss_1 = np.sum(np.log(y_proba[y == 1] + 1e-30))\n",
        "    logloss_0 = np.sum(np.log(1 - y_proba[y == 0] + 1e-30))\n",
        "    logloss_total = -(logloss_0 + logloss_1) / len(y)\n",
        "    return logloss_total\n",
        "\n",
        "\n",
        "def gr_logloss(X, W, y):\n",
        "    y_proba = sigmoid(X @ W)\n",
        "    grad = X.T @ (y_proba - y)\n",
        "    return grad"
      ],
      "metadata": {
        "id": "IU1LLxjP4Lvs"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nesterov\n",
        "# установка минимального значения, на которое должны изменяться веса\n",
        "eps = 0.0001\n",
        "\n",
        "# первоначальня точка\n",
        "#np.random.seed(2)\n",
        "W = np.random.randn(X.shape[1])\n",
        "W = np.where(W == 1, 1, 1)\n",
        "cur_imp = np.where(W == 1, 0, 0)\n",
        "\n",
        "# размер шага (learning rate)\n",
        "learning_rate = 0.01\n",
        "\n",
        "next_W = W\n",
        "\n",
        "# количество итераций\n",
        "n = 100\n",
        "for i in range(n):\n",
        "    cur_W = next_W\n",
        "\n",
        "    # движение в негативную сторону вычисляемого градиента\n",
        "    # next_W = cur_W - learning_rate * gr_logloss(X, cur_W, y)\n",
        "    next_imp = g * cur_imp + learning_rate * gr_logloss(X, cur_W - g * cur_imp, y)\n",
        "    next_W = cur_W - next_imp\n",
        "\n",
        "    # остановка когда достигнута необходимая степень точности\n",
        "    if np.linalg.norm(cur_W - next_W) <= eps:\n",
        "        break\n",
        "\n",
        "    if i % 1 == 0:\n",
        "        print(f\"Итерация: {i}\")\n",
        "        y_proba = sigmoid(X @ next_W)\n",
        "        y_class = np.where(y_proba >= 0.5, 1, 0)\n",
        "        accuracy = (y_class == y).sum() / len(y)\n",
        "        print(f\"Logloss {logloss(y, y_proba)}\")\n",
        "        print(f\"Accuracy {accuracy}\")\n",
        "        print(\"--------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_g70JMZ5JEZ",
        "outputId": "e502fddd-52c5-4677-d513-e4cd49a633a7"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Итерация: 0\n",
            "Logloss 1.2910308882282424\n",
            "Accuracy 0.22\n",
            "--------------------------------------------------------\n",
            "Итерация: 1\n",
            "Logloss 0.47971328600027185\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 2\n",
            "Logloss 0.33937215184892267\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 3\n",
            "Logloss 0.29230496367120734\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 4\n",
            "Logloss 0.26469821673069044\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 5\n",
            "Logloss 0.2452868216750972\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 6\n",
            "Logloss 0.23036939240585455\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 7\n",
            "Logloss 0.21829776410980814\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 8\n",
            "Logloss 0.20819857415842297\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 9\n",
            "Logloss 0.19955260272363154\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 10\n",
            "Logloss 0.19202481974068022\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 11\n",
            "Logloss 0.1853854621575023\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 12\n",
            "Logloss 0.1794694315592929\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 13\n",
            "Logloss 0.17415368228465133\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 14\n",
            "Logloss 0.1693438023107212\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 15\n",
            "Logloss 0.16496562312164506\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 16\n",
            "Logloss 0.16095974040128677\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 17\n",
            "Logloss 0.15727780161023805\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 18\n",
            "Logloss 0.1538799105880311\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 19\n",
            "Logloss 0.15073276359554602\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 20\n",
            "Logloss 0.14780827919357656\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 21\n",
            "Logloss 0.145082570594238\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 22\n",
            "Logloss 0.14253516118397744\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 23\n",
            "Logloss 0.140148376346284\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 24\n",
            "Logloss 0.13790686548689618\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 25\n",
            "Logloss 0.13579722181297682\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 26\n",
            "Logloss 0.13380767659145346\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 27\n",
            "Logloss 0.13192785090639544\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 28\n",
            "Logloss 0.13014855233630654\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 29\n",
            "Logloss 0.12846160710229337\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 30\n",
            "Logloss 0.12685972049923736\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 31\n",
            "Logloss 0.1253363600790288\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 32\n",
            "Logloss 0.12388565728504648\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 33\n",
            "Logloss 0.12250232416134256\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 34\n",
            "Logloss 0.12118158246216172\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 35\n",
            "Logloss 0.11991910302630977\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 36\n",
            "Logloss 0.11871095369835444\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 37\n",
            "Logloss 0.1175535544048703\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 38\n",
            "Logloss 0.11644363825093137\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 39\n",
            "Logloss 0.11537821770602288\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 40\n",
            "Logloss 0.11435455511156153\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 41\n",
            "Logloss 0.11337013687335443\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 42\n",
            "Logloss 0.11242265080846466\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 43\n",
            "Logloss 0.11150996620234854\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 44\n",
            "Logloss 0.1106301162028342\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 45\n",
            "Logloss 0.10978128223566436\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 46\n",
            "Logloss 0.10896178017438783\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 47\n",
            "Logloss 0.10817004803728102\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 48\n",
            "Logloss 0.1074046350172436\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 49\n",
            "Logloss 0.106664191678455\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 50\n",
            "Logloss 0.10594746117697344\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 51\n",
            "Logloss 0.1052532713821904\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 52\n",
            "Logloss 0.1045805277927505\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 53\n",
            "Logloss 0.10392820715472383\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 54\n",
            "Logloss 0.10329535170189516\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 55\n",
            "Logloss 0.10268106394835018\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 56\n",
            "Logloss 0.10208450197238\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 57\n",
            "Logloss 0.10150487513832152\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 58\n",
            "Logloss 0.10094144020949346\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 59\n",
            "Logloss 0.10039349781104169\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 60\n",
            "Logloss 0.09986038920640052\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 61\n",
            "Logloss 0.09934149335532445\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 62\n",
            "Logloss 0.09883622422514043\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 63\n",
            "Logloss 0.09834402833009133\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 64\n",
            "Logloss 0.09786438247645654\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 65\n",
            "Logloss 0.09739679169360016\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 66\n",
            "Logloss 0.096940787333258\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 67\n",
            "Logloss 0.09649592532127539\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 68\n",
            "Logloss 0.09606178454768118\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 69\n",
            "Logloss 0.0956379653824586\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 70\n",
            "Logloss 0.0952240883056787\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 71\n",
            "Logloss 0.09481979264181672\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 72\n",
            "Logloss 0.0944247353890954\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 73\n",
            "Logloss 0.09403859013560935\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 74\n",
            "Logloss 0.09366104605479243\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 75\n",
            "Logloss 0.09329180697351226\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 76\n",
            "Logloss 0.0929305905067173\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 77\n",
            "Logloss 0.09257712725313791\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 78\n",
            "Logloss 0.0922311600470562\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 79\n",
            "Logloss 0.09189244326161969\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 80\n",
            "Logloss 0.09156074215958794\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 81\n",
            "Logloss 0.09123583228777184\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 82\n",
            "Logloss 0.09091749891175921\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 83\n",
            "Logloss 0.09060553648782121\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 84\n",
            "Logloss 0.09029974816916564\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 85\n",
            "Logloss 0.08999994534394665\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 86\n",
            "Logloss 0.08970594720266334\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 87\n",
            "Logloss 0.0894175803327786\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 88\n",
            "Logloss 0.0891346783385715\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 89\n",
            "Logloss 0.08885708148440048\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 90\n",
            "Logloss 0.08858463635970466\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 91\n",
            "Logloss 0.08831719556420531\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 92\n",
            "Logloss 0.08805461741189329\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 93\n",
            "Logloss 0.08779676565250089\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 94\n",
            "Logloss 0.08754350920925834\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 95\n",
            "Logloss 0.08729472193182886\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 96\n",
            "Logloss 0.08705028236340183\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 97\n",
            "Logloss 0.08681007352100079\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 98\n",
            "Logloss 0.08657398268813482\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 99\n",
            "Logloss 0.08634190121898762\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучим логистическую регрессию при помощи метода скользящего среднего (Root Mean Square Propagation, RMSProp)"
      ],
      "metadata": {
        "id": "uHE05dQFJRkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RMSProp\n",
        "# установка минимального значения, на которое должны изменяться веса\n",
        "a=0.1\n",
        "\n",
        "eps = 0.0001\n",
        "\n",
        "# первоначальня точка\n",
        "#np.random.seed(2)\n",
        "W = np.random.randn(X.shape[1])\n",
        "W = np.where(W == 1, 1, 1)\n",
        "cur_g = np.where(W == 1, 0, 0)\n",
        "\n",
        "# размер шага (learning rate)\n",
        "learning_rate = 0.01\n",
        "\n",
        "next_W = W\n",
        "\n",
        "# количество итераций\n",
        "n = 60\n",
        "for i in range(n):\n",
        "    cur_W = next_W\n",
        "\n",
        "    # движение в негативную сторону вычисляемого градиента\n",
        "    # next_W = cur_W - learning_rate * gr_logloss(X, cur_W, y)\n",
        "    next_g = a * cur_g + (1-a) * np.square(gr_logloss(X, cur_W, y))\n",
        "    next_W = cur_W - learning_rate * gr_logloss(X, cur_W, y) / (np.sqrt(g)+eps)\n",
        "\n",
        "    # остановка когда достигнута необходимая степень точности\n",
        "    if np.linalg.norm(cur_W - next_W) <= eps:\n",
        "        break\n",
        "\n",
        "    if i % 1 == 0:\n",
        "        print(f\"Итерация: {i}\")\n",
        "        y_proba = sigmoid(X @ next_W)\n",
        "        y_class = np.where(y_proba >= 0.5, 1, 0)\n",
        "        accuracy = (y_class == y).sum() / len(y)\n",
        "        print(f\"Logloss {logloss(y, y_proba)}\")\n",
        "        print(f\"Accuracy {accuracy}\")\n",
        "        print(\"--------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYhyOS0sJach",
        "outputId": "3be875c8-af2d-474d-be5b-9c2c902f62cd"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Итерация: 0\n",
            "Logloss 1.2571654377555885\n",
            "Accuracy 0.23\n",
            "--------------------------------------------------------\n",
            "Итерация: 1\n",
            "Logloss 0.45981543886056625\n",
            "Accuracy 0.93\n",
            "--------------------------------------------------------\n",
            "Итерация: 2\n",
            "Logloss 0.3327757478879411\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 3\n",
            "Logloss 0.28797760415365664\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 4\n",
            "Logloss 0.2612509675826993\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 5\n",
            "Logloss 0.2422988106219374\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 6\n",
            "Logloss 0.22766424656059267\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 7\n",
            "Logloss 0.2157875587634864\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 8\n",
            "Logloss 0.20583422255937756\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 9\n",
            "Logloss 0.19730429771631683\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 10\n",
            "Logloss 0.18987318327698566\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 11\n",
            "Logloss 0.1833171369855041\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 12\n",
            "Logloss 0.1774747243911115\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 13\n",
            "Logloss 0.17222523274196017\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 14\n",
            "Logloss 0.16747579711445204\n",
            "Accuracy 0.95\n",
            "--------------------------------------------------------\n",
            "Итерация: 15\n",
            "Logloss 0.16315331451563872\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 16\n",
            "Logloss 0.15919914119780373\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 17\n",
            "Logloss 0.15556548624402308\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 18\n",
            "Logloss 0.1522128816510595\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 19\n",
            "Logloss 0.14910835986195717\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 20\n",
            "Logloss 0.14622411055059525\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 21\n",
            "Logloss 0.14353647080358636\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 22\n",
            "Logloss 0.14102515270701485\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 23\n",
            "Logloss 0.1386726434980673\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 24\n",
            "Logloss 0.13646373345710855\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 25\n",
            "Logloss 0.1343851399032186\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 26\n",
            "Logloss 0.13242520454435305\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 27\n",
            "Logloss 0.13057364754807008\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 28\n",
            "Logloss 0.12882136598466923\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 29\n",
            "Logloss 0.1271602673499589\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 30\n",
            "Logloss 0.1255831310868917\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 31\n",
            "Logloss 0.12408349264950705\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 32\n",
            "Logloss 0.122655545860684\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 33\n",
            "Logloss 0.12129406022444648\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 34\n",
            "Logloss 0.11999431054536752\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 35\n",
            "Logloss 0.11875201673928411\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 36\n",
            "Logloss 0.11756329213191734\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 37\n",
            "Logloss 0.1164245988646012\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 38\n",
            "Logloss 0.1153327092807098\n",
            "Accuracy 0.96\n",
            "--------------------------------------------------------\n",
            "Итерация: 39\n",
            "Logloss 0.11428467236844586\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 40\n",
            "Logloss 0.11327778449727553\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 41\n",
            "Logloss 0.11230956381539581\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 42\n",
            "Logloss 0.11137772778097778\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 43\n",
            "Logloss 0.11048017338572691\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 44\n",
            "Logloss 0.10961495969954552\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 45\n",
            "Logloss 0.10878029242287582\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 46\n",
            "Logloss 0.107974510181077\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 47\n",
            "Logloss 0.10719607233485794\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 48\n",
            "Logloss 0.10644354811386453\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 49\n",
            "Logloss 0.1057156069082101\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 50\n",
            "Logloss 0.10501100957600651\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 51\n",
            "Logloss 0.10432860064457859\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 52\n",
            "Logloss 0.10366730129965142\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 53\n",
            "Logloss 0.1030261030709017\n",
            "Accuracy 0.97\n",
            "--------------------------------------------------------\n",
            "Итерация: 54\n",
            "Logloss 0.10240406213427455\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 55\n",
            "Logloss 0.10180029416172719\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 56\n",
            "Logloss 0.10121396965785173\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 57\n",
            "Logloss 0.10064430973038192\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 58\n",
            "Logloss 0.10009058224809296\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n",
            "Итерация: 59\n",
            "Logloss 0.09955209834522381\n",
            "Accuracy 0.98\n",
            "--------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод\n",
        "\n",
        "Модель градиентного спуска и Метод Нестерова показали одинаковую точность и скорость, Метод скользящего среднего достиг такой же точности за меньшее количество итераций.\n",
        "\n",
        "\n",
        "|Метод градиентного спуска|\n",
        "\n",
        "- Итерация: 56\n",
        "\n",
        "- Logloss 0.10208450197238\n",
        "\n",
        "- Accuracy 0.98\n",
        "\n",
        "\n",
        "|Метод Нестерова|\n",
        "\n",
        "- Итерация: 56\n",
        "\n",
        "- Logloss 0.10208450197238\n",
        "\n",
        "- Accuracy 0.98\n",
        "\n",
        "\n",
        "\n",
        "|Метод скользящего среднего|\n",
        "\n",
        "- Итерация: 54\n",
        "\n",
        "- Logloss 0.10240406213427455\n",
        "\n",
        "- Accuracy 0.98\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CM8wCdmDEa5R"
      }
    }
  ]
}